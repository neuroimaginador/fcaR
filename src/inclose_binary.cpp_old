#include <Rcpp.h>
#include <Rcpp/Benchmark/Timer.h>
#include "aux_functions.h"
#include "vector_operations.h" // Incluimos explícitamente para v7
#include <vector>
#include <algorithm>

// --- DEPENDENCIAS SIMD HÍBRIDAS ---
#if defined(__aarch64__) || defined(_M_ARM64)
#include <arm_neon.h> // Para NEON en ARM (Apple Silicon)
#elif defined(__x86_64__) || defined(_M_X64)
#include <immintrin.h> // Para AVX2 en Intel/AMD
#endif

// --- Dependencia para optimizaciones ---
#include <boost/dynamic_bitset.hpp>

#ifdef _MSC_VER
#include <intrin.h>
#define __builtin_popcountll __popcnt64
#endif

using namespace Rcpp;

// =============================================================================
// --- VERSIÓN 1: IMPLEMENTACIÓN ORIGINAL (RENOMBRADA) ---
// =============================================================================
// (El código de InClose_binary_original permanece aquí, idéntico al anterior)
// ...
// ... (código v1 omitido por brevedad) ...
// ...


// =============================================================================
// --- VERSIÓN 2: OPTIMIZADA CON BITSETS (RENOMBRADA) ---
// =============================================================================

// --- Definiciones de tipos para claridad ---
using Bitset_v2 = boost::dynamic_bitset<>;
using Extent_v2 = std::vector<int>;
using AttributeCols_v2 = std::vector<Bitset_v2>;
using ObjectRows_v2 = std::vector<Bitset_v2>;

// Test de canonicidad v2 (Coste: O(j * |new_extent|))
bool is_canonical_fast_v2(const AttributeCols_v2& attr_cols,
                          const Extent_v2& new_extent,
                          const Bitset_v2& parent_intent,
                          int j,
                          double* all_att_intents) {

  for (int k = 0; k < j; k++) {
    if (parent_intent.test(k)) continue;
    (*all_att_intents) += 1.0;
    const auto& attr_k_bits = attr_cols[k];
    bool has_all_attributes = true;
    for (int obj_idx : new_extent) {
      if (!attr_k_bits.test(obj_idx)) {
        has_all_attributes = false;
        break;
      }
    }
    if (has_all_attributes) {
      return false;
    }
  }
  return true;
}

// Core recursivo v2
void inclose_fast_core_v2(int y,
                          int n_objects,
                          int n_attributes,
                          Extent_v2& extent,
                          Bitset_v2& intent,
                          const AttributeCols_v2& attr_cols,
                          const ObjectRows_v2& obj_rows,
                          SparseVector* extents_out,
                          DoubleArray* intents_out,
                          double* canonicity_tests,
                          double* all_att_intents) {

  // 1. Guardar el concepto (E/S en bucle caliente)
  SparseVector current_extent;
  initVector(&current_extent, n_objects);
  for(int obj : extent) {
    insertArray(&current_extent.i, obj);
    insertArray(&current_extent.x, 1.0);
  }
  add_column(extents_out, current_extent);
  freeVector(&current_extent);

  for (int attr = 0; attr < n_attributes; ++attr) {
    insertArray(intents_out, intent.test(attr) ? 1.0 : 0.0);
  }

  // 2. Iterar
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 3. Calcular new_extent
    Extent_v2 new_extent;
    new_extent.reserve(extent.size());
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        new_extent.push_back(obj_idx);
      }
    }

    if (new_extent.empty()) continue;

    // 4. Calcular new_intent (Clausura Rápida)
    Bitset_v2 new_intent(n_attributes);
    new_intent.set();
    for (int obj_idx : new_extent) {
      new_intent &= obj_rows[obj_idx];
    }

    // 5. Test de Canonicidad (Llamada a v2)
    (*canonicity_tests) += 1.0;
    if (is_canonical_fast_v2(attr_cols, new_extent, intent, j, all_att_intents)) {
      // 6. Recursión
      inclose_fast_core_v2(j, n_objects, n_attributes,
                           new_extent, new_intent,
                           attr_cols, obj_rows,
                           extents_out, intents_out,
                           canonicity_tests, all_att_intents);
    }
  }
}

// [[Rcpp::export]]
List InClose_binary_fast_v2(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {
  Timer timer;
  timer.step("start_v2_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  AttributeCols_v2 attr_cols(n_attributes, Bitset_v2(n_objects));
  ObjectRows_v2 obj_rows(n_objects, Bitset_v2(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents;
  DoubleArray intents;
  initVector(&extents, n_objects);
  initArray(&intents, n_attributes);

  Extent_v2 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v2 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v2_recursion");
  inclose_fast_core_v2(-1, n_objects, n_attributes,
                       initial_extent, initial_intent,
                       attr_cols, obj_rows,
                       &extents, &intents,
                       &canonicity_tests, &all_att_intents);
                       timer.step("end_v2_recursion");

                       S4 intents_S4 = DenseArrayToS4(intents, n_attributes);
                       S4 extents_S4 = SparseToS4_fast(extents);
                       freeVector(&extents);
                       freeArray(&intents);
                       timer.step("end_v2_packaging");

                       List res = List::create(
                         _["intents"] = intents_S4,
                         _["extents"] = extents_S4,
                         _["total"] = (intents.used > 0) ? (intents.used / n_attributes) : 0,
                         _["tests"] = canonicity_tests,
                         _["att_intents"] = all_att_intents,
                         _["timer"] = timer);
                       return res;
}


// =============================================================================
// --- VERSIÓN 3: EXTREME (Canonicidad O(j) + E/S Amortizada) ---
// =============================================================================

// --- Definiciones de tipos para v3 ---
using Bitset = boost::dynamic_bitset<>;
using Extent = std::vector<int>; // Sigue siendo disperso
using AttributeCols = std::vector<Bitset>;
using ObjectRows = std::vector<Bitset>;

/**
 * @brief Core recursivo v3.
 * NO escribe en la salida, solo almacena en vectores C++.
 */
void inclose_fast_core_v3(int y,
                          int n_objects,
                          int n_attributes,
                          Extent& extent,      // Extent actual (disperso)
                          Bitset& intent,      // Intent actual (bitset denso)
                          const AttributeCols& attr_cols, // Matriz (columnas)
                          const ObjectRows& obj_rows,    // Matriz (filas)
                          std::vector<Extent>& all_extents_out, // Salida C++
                          std::vector<Bitset>& all_intents_out, // Salida C++
                          double* canonicity_tests,
                          double* all_att_intents) {

  // 1. Guardar el concepto (E/S Amortizada: solo push_back)
  all_extents_out.push_back(extent);
  all_intents_out.push_back(intent);

  // 2. Iterar
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 3. Calcular new_extent (Intersección: extent ∩ attr_cols[j])
    Extent new_extent;
    new_extent.reserve(extent.size());
    const auto& attr_j_bits = attr_cols[j];

    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        new_extent.push_back(obj_idx);
      }
    }

    if (new_extent.empty()) continue;

    // 4. Calcular new_intent (Clausura Rápida)
    Bitset new_intent(n_attributes);
    new_intent.set();
    for (int obj_idx : new_extent) {
      new_intent &= obj_rows[obj_idx];
    }

    // 5. Test de Canonicidad (OPTIMIZADO V3: Coste O(j))
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    for (int k = 0; k < j; k++) {
      // Si la intención padre no tenía 'k', pero la nueva clausura sí...
      if (!intent.test(k) && new_intent.test(k)) {
        is_canonical = false;
        // El test de canonicidad falla, pero 'all_att_intents'
        // debe seguir contando como si el test se hubiera completado.
      }

      // Contamos todos los tests de atributos que haríamos
      if (!intent.test(k)) {
        (*all_att_intents) += 1.0;
      }
    }

    // 6. Recursión
    if (is_canonical) {
      inclose_fast_core_v3(j, n_objects, n_attributes,
                           new_extent, new_intent,
                           attr_cols, obj_rows,
                           all_extents_out, all_intents_out,
                           canonicity_tests, all_att_intents);
    }
  }
}

/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v3.
 */
// [[Rcpp::export]]
List InClose_binary_fast_v3(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {

  Timer timer;
  timer.step("start_v3_setup");

  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols attr_cols(n_attributes, Bitset(n_objects));
  ObjectRows obj_rows(n_objects, Bitset(n_attributes));

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida C++
  double canonicity_tests = 0;
  double all_att_intents = 0;
  std::vector<Extent> all_extents;
  std::vector<Bitset> all_intents;

  // 3. Calcular el concepto inicial (top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  // Pre-reservar espacio (estimación conservadora)
  all_extents.reserve(n_objects * n_attributes);
  all_intents.reserve(n_objects * n_attributes);

  timer.step("start_v3_recursion");

  // 4. Iniciar la recursión (versión v3)
  inclose_fast_core_v3(-1, n_objects, n_attributes,
                       initial_extent, initial_intent,
                       attr_cols, obj_rows,
                       all_extents, all_intents, // Salida C++
                       &canonicity_tests, &all_att_intents);

  timer.step("end_v3_recursion");

  // 5. Empaquetar resultados (E/S Amortizada)
  // Ahora convertimos la salida C++ a las estructuras de R, una sola vez.
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects);
  initArray(&intents_out, n_attributes);

  int total_concepts = all_extents.size();

  for (int i = 0; i < total_concepts; ++i) {
    // Copiar Extent
    const auto& ext = all_extents[i];
    SparseVector current_extent;
    initVector(&current_extent, n_objects);
    for(int obj : ext) {
      insertArray(&current_extent.i, obj);
      insertArray(&current_extent.x, 1.0);
    }
    add_column(&extents_out, current_extent);
    freeVector(&current_extent);

    // Copiar Intent
    const auto& intent_bits = all_intents[i];
    for (int attr = 0; attr < n_attributes; ++attr) {
      insertArray(&intents_out, intent_bits.test(attr) ? 1.0 : 0.0);
    }
  }

  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_v3_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);

  return res;
}

// =============================================================================
// --- VERSIÓN 4: SUPER-OPTIMIZADA (v2 + Canonicidad O(j)) ---
// =============================================================================

// --- Definiciones de tipos para v4 ---
using Bitset_v4 = boost::dynamic_bitset<>;
using Extent_v4 = std::vector<int>;
using AttributeCols_v4 = std::vector<Bitset_v4>;
using ObjectRows_v4 = std::vector<Bitset_v4>;

/**
 * @brief Core recursivo v4.
 * Usa la E/S directa de v2 y el test de canonicidad O(j) de v3.
 */
void inclose_fast_core_v4(int y,
                          int n_objects,
                          int n_attributes,
                          Extent_v4& extent,
                          Bitset_v4& intent,
                          const AttributeCols_v4& attr_cols,
                          const ObjectRows_v4& obj_rows,
                          SparseVector* extents_out,
                          DoubleArray* intents_out,
                          double* canonicity_tests,
                          double* all_att_intents) {

  // 1. Guardar el concepto (E/S directa v2)
  SparseVector current_extent;
  initVector(&current_extent, n_objects);
  for(int obj : extent) {
    insertArray(&current_extent.i, obj);
    insertArray(&current_extent.x, 1.0);
  }
  add_column(extents_out, current_extent);
  freeVector(&current_extent);

  for (int attr = 0; attr < n_attributes; ++attr) {
    insertArray(intents_out, intent.test(attr) ? 1.0 : 0.0);
  }

  // 2. Iterar
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 3. Calcular new_extent
    Extent_v4 new_extent;
    new_extent.reserve(extent.size());
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        new_extent.push_back(obj_idx);
      }
    }

    if (new_extent.empty()) continue;

    // 4. Calcular new_intent (Clausura Rápida v2)
    Bitset_v4 new_intent(n_attributes);
    new_intent.set();
    for (int obj_idx : new_extent) {
      new_intent &= obj_rows[obj_idx];
    }

    // 5. Test de Canonicidad (OPTIMIZADO V4: Coste O(j) con break)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      // Si k ya estaba en la intención padre, saltar.
      if (intent.test(k)) continue;

      // Contamos esto como un test de atributo
      (*all_att_intents) += 1.0;

      // Si la nueva clausura (new_intent) "recogió" un atributo k < j...
      if (new_intent.test(k)) {
        // ...entonces no es canónico.
        is_canonical = false;
        break; // ¡Fundamental! Dejar de testear.
      }
    }

    // 6. Recursión
    if (is_canonical) {
      inclose_fast_core_v4(j, n_objects, n_attributes,
                           new_extent, new_intent,
                           attr_cols, obj_rows,
                           extents_out, intents_out,
                           canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v4.
 */
// [[Rcpp::export]]
List InClose_binary_fast_v4(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {
  Timer timer;
  timer.step("start_v4_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v4 attr_cols(n_attributes, Bitset_v4(n_objects));
  ObjectRows_v4 obj_rows(n_objects, Bitset_v4(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents;
  DoubleArray intents;
  initVector(&extents, n_objects);
  initArray(&intents, n_attributes);

  // 3. Calcular el concepto inicial (top)
  Extent_v4 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v4 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v4_recursion");

  // 4. Iniciar la recursión (versión v4)
  inclose_fast_core_v4(-1, n_objects, n_attributes,
                       initial_extent, initial_intent,
                       attr_cols, obj_rows,
                       &extents, &intents,
                       &canonicity_tests, &all_att_intents);

                       timer.step("end_v4_recursion");

                       // 5. Empaquetar resultados
                       S4 intents_S4 = DenseArrayToS4(intents, n_attributes);
                       S4 extents_S4 = SparseToS4_fast(extents);
                       freeVector(&extents);
                       freeArray(&intents);

                       timer.step("end_v4_packaging");

                       List res = List::create(
                         _["intents"] = intents_S4,
                         _["extents"] = extents_S4,
                         _["total"] = (intents.used > 0) ? (intents.used / n_attributes) : 0,
                         _["tests"] = canonicity_tests,
                         _["att_intents"] = all_att_intents,
                         _["timer"] = timer);
                       return res;
}


// =============================================================================
// --- VERSIÓN 5: MÁXIMA (v4 + Reutilización de Memoria) ---
// =============================================================================

// --- Definiciones de tipos para v5 ---
using Bitset_v5 = boost::dynamic_bitset<>;
using Extent_v5 = std::vector<int>;
using AttributeCols_v5 = std::vector<Bitset_v5>;
using ObjectRows_v5 = std::vector<Bitset_v5>;

/**
 * @brief Core recursivo v5.
 * Mueve la asignación de memoria fuera del bucle 'j'.
 */
void inclose_fast_core_v5(int y,
                          int n_objects,
                          int n_attributes,
                          Extent_v5& extent,      // Concepto actual
                          Bitset_v5& intent,      // Concepto actual
                          const AttributeCols_v5& attr_cols,
                          const ObjectRows_v5& obj_rows,
                          SparseVector* extents_out,
                          DoubleArray* intents_out,
                          double* canonicity_tests,
                          double* all_att_intents) {

  // 1. Guardar el concepto (E/S directa v2/v4)
  SparseVector current_extent;
  initVector(&current_extent, n_objects);
  for(int obj : extent) {
    insertArray(&current_extent.i, obj);
    insertArray(&current_extent.x, 1.0);
  }
  add_column(extents_out, current_extent);
  freeVector(&current_extent);

  for (int attr = 0; attr < n_attributes; ++attr) {
    insertArray(intents_out, intent.test(attr) ? 1.0 : 0.0);
  }

  // 2. *** OPTIMIZACIÓN V5: Asignación de memoria ÚNICA ***
  // Asignamos memoria para los "hijos" UNA VEZ, fuera del bucle.
  Extent_v5 child_extent;
  child_extent.reserve(extent.size()); // Reservamos capacidad una vez
  Bitset_v5 child_intent(n_attributes);

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 4. Calcular child_extent (REUTILIZANDO 'child_extent')
    child_extent.clear(); // <-- Vaciamos el vector (no libera memoria)

    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx); // Rellenamos
      }
    }

    if (child_extent.empty()) continue;

    // 5. Calcular child_intent (REUTILIZANDO 'child_intent')
    child_intent.set(); // <-- Reseteamos el bitset (no reasigna)
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 6. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;

      (*all_att_intents) += 1.0;

      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      // Llamamos recursivamente.
      // 'child_extent' y 'child_intent' se copian en el
      // stack de la nueva llamada (como 'extent' e 'intent').
      inclose_fast_core_v5(j, n_objects, n_attributes,
                           child_extent, child_intent,
                           attr_cols, obj_rows,
                           extents_out, intents_out,
                           canonicity_tests, all_att_intents);
    }
    // El bucle 'j' continúa, reutilizando la memoria de
    // 'child_extent' y 'child_intent' en la siguiente iteración.
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v5.
 */
// [[Rcpp::export]]
List InClose_binary_fast_v5(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {
  Timer timer;
  timer.step("start_v5_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v5 attr_cols(n_attributes, Bitset_v5(n_objects));
  ObjectRows_v5 obj_rows(n_objects, Bitset_v5(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents;
  DoubleArray intents;
  initVector(&extents, n_objects);
  initArray(&intents, n_attributes);

  // 3. Calcular el concepto inicial (top)
  Extent_v5 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v5 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v5_recursion");

  // 4. Iniciar la recursión (versión v5)
  inclose_fast_core_v5(-1, n_objects, n_attributes,
                       initial_extent, initial_intent,
                       attr_cols, obj_rows,
                       &extents, &intents,
                       &canonicity_tests, &all_att_intents);

                       timer.step("end_v5_recursion");

                       // 5. Empaquetar resultados
                       S4 intents_S4 = DenseArrayToS4(intents, n_attributes);
                       S4 extents_S4 = SparseToS4_fast(extents);
                       freeVector(&extents);
                       freeArray(&intents);

                       timer.step("end_v5_packaging");

                       List res = List::create(
                         _["intents"] = intents_S4,
                         _["extents"] = extents_S4,
                         _["total"] = (intents.used > 0) ? (intents.used / n_attributes) : 0,
                         _["tests"] = canonicity_tests,
                         _["att_intents"] = all_att_intents,
                         _["timer"] = timer);
                       return res;
}

// =============================================================================
// --- VERSIÓN 6: FINAL (v5 + Reutilización de E/S) ---
// =============================================================================

// --- Definiciones de tipos para v6 ---
using Bitset_v6 = boost::dynamic_bitset<>;
using Extent_v6 = std::vector<int>;
using AttributeCols_v6 = std::vector<Bitset_v6>;
using ObjectRows_v6 = std::vector<Bitset_v6>;

/**
 * @brief Core recursivo v6.
 * Reutiliza un búfer de E/S (extent_buffer) para evitar
 * asignaciones al guardar cada concepto.
 */
void inclose_fast_core_v6(int y,
                          int n_objects,
                          int n_attributes,
                          Extent_v6& extent,      // Concepto actual
                          Bitset_v6& intent,      // Concepto actual
                          const AttributeCols_v6& attr_cols,
                          const ObjectRows_v6& obj_rows,
                          SparseVector* extents_out,
                          DoubleArray* intents_out,
                          SparseVector& extent_buffer, // <-- BÚFER DE E/S REUTILIZABLE
                          double* canonicity_tests,
                          double* all_att_intents) {

  // 1. *** OPTIMIZACIÓN V6: Guardar el concepto (E/S reutilizable) ***

  // Reutilizamos el búfer de E/S
  reinitVector(&extent_buffer); // <-- Vaciamos el búfer (O(1))
  for(int obj : extent) {
    insertArray(&extent_buffer.i, obj);
    insertArray(&extent_buffer.x, 1.0);
  }
  add_column(extents_out, extent_buffer); // Sigue copiando, pero sin re-asignar

  // Guardar Intent (sigue siendo O(M), pero la asignación de extent era peor)
  for (int attr = 0; attr < n_attributes; ++attr) {
    insertArray(intents_out, intent.test(attr) ? 1.0 : 0.0);
  }

  // 2. Asignación de memoria ÚNICA (v5)
  Extent_v6 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v6 child_intent(n_attributes);

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 4. Calcular child_extent (REUTILIZANDO 'child_extent')
    child_extent.clear();
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 5. Calcular child_intent (REUTILIZANDO 'child_intent')
    child_intent.set();
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 6. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v6(j, n_objects, n_attributes,
                           child_extent, child_intent,
                           attr_cols, obj_rows,
                           extents_out, intents_out,
                           extent_buffer, // <-- Pasamos el búfer
                           canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v6.
 */
// [[Rcpp::export]]
List InClose_binary_fast_v6(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {
  Timer timer;
  timer.step("start_v6_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v6 attr_cols(n_attributes, Bitset_v6(n_objects));
  ObjectRows_v6 obj_rows(n_objects, Bitset_v6(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents;
  DoubleArray intents;
  initVector(&extents, n_objects);
  initArray(&intents, n_attributes);

  // 3. *** OPTIMIZACIÓN V6: Crear el búfer de E/S UNA VEZ ***
  SparseVector extent_io_buffer;
  initVector(&extent_io_buffer, n_objects);

  // 4. Calcular el concepto inicial (top)
  Extent_v6 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v6 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v6_recursion");

  // 5. Iniciar la recursión (versión v6)
  inclose_fast_core_v6(-1, n_objects, n_attributes,
                       initial_extent, initial_intent,
                       attr_cols, obj_rows,
                       &extents, &intents,
                       extent_io_buffer, // <-- Pasamos el búfer
                       &canonicity_tests, &all_att_intents);

  timer.step("end_v6_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents);

  // 7. Liberar el búfer de E/S
  freeVector(&extent_io_buffer);

  freeVector(&extents);
  freeArray(&intents);

  timer.step("end_v6_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents.used > 0) ? (intents.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 7: CORREGIDA (v6 + E/S Intent a Granel) ---
// =============================================================================

// =============================================================================
// --- VERSIÓN 8 (v7 CORREGIDA): (v6 + E/S Intent a Granel + Arreglo Crash) ---
// =============================================================================

// =============================================================================
// --- VERSIÓN 9 (v8 ESTABLE): (v6 + E/S Intent a Granel + Gestión de Memoria C) ---
// =============================================================================

// --- Definiciones de tipos para v9 (idénticas a v8) ---
using Bitset_v9 = boost::dynamic_bitset<>;
using Extent_v9 = std::vector<int>;
using AttributeCols_v9 = std::vector<Bitset_v9>;
using ObjectRows_v9 = std::vector<Bitset_v9>;

/**
 * @brief Helper para v9 (ESTABLE)
 * Asegura espacio usando 'realloc', coincidiendo con vector_operations.cpp
 */
inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
  if (a->used + additional_size > a->size) {
    size_t newSize = (a->size + additional_size) * 1.5;
    if (newSize == 0) newSize = 1;

    // *** ¡LA CORRECCIÓN V9! ***
    // Usamos realloc, no R_alloc, para coincidir con
    // la gestión de memoria de initArray/freeArray
    double* tmp = (double *)realloc(a->array, newSize * sizeof(double));

    if (tmp == NULL) {
      Rcpp::stop("Failed to realloc memory in ensureArray_double_v9");
    }

    a->array = tmp;
    a->size = newSize;

    // Rellenamos la nueva memoria con 0,
    // como hace la implementación original de insertArray
    for (size_t i = a->used; i < a->size; i++) {
      a->array[i] = 0;
    }
  }
}

/**
 * @brief Helper para v9 (ESTABLE)
 * Copia un bloque de 'n' dobles en el DoubleArray de una sola vez.
 */
inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
  // 1. Asegurar espacio (UNA VEZ)
  ensureArray_double_v9(a, n); // <-- Llama a la versión v9 (segura)

  // 2. Copiar a granel (memcpy)
  memcpy(&a->array[a->used], buffer, n * sizeof(double));

  // 3. Actualizar contador
  a->used += n;
}

/**
 * @brief Core recursivo v9.
 */
void inclose_fast_core_v9(int y,
                          int n_objects,
                          int n_attributes,
                          Extent_v9& extent,      // Concepto actual
                          Bitset_v9& intent,      // Concepto actual
                          const AttributeCols_v9& attr_cols,
                          const ObjectRows_v9& obj_rows,
                          SparseVector* extents_out,
                          DoubleArray* intents_out,
                          SparseVector& extent_buffer, // Búfer E/S v6
                          double* intent_buffer,       // Búfer E/S v7
                          double* canonicity_tests,
                          double* all_att_intents) {

  // 1. Guardar Extent (E/S reutilizable v6)
  reinitVector(&extent_buffer);
  for(int obj : extent) {
    insertArray(&extent_buffer.i, obj);
    insertArray(&extent_buffer.x, 1.0);
  }
  add_column(extents_out, extent_buffer);

  // 2. Optimización V7: Guardar Intent (E/S a granel)

  // 2a. Llenar el búfer local (rápido, en caché)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }

  // 2b. Volcar el búfer a la salida (1 check + memcpy)
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v9 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v9 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Calcular child_extent (REUTILIZANDO 'child_extent')
    child_extent.clear();
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 6. Calcular child_intent (REUTILIZANDO 'child_intent')
    child_intent.set();
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 7. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 8. Recursión
    if (is_canonical) {
      inclose_fast_core_v9(j, n_objects, n_attributes,
                           child_extent, child_intent,
                           attr_cols, obj_rows,
                           extents_out, intents_out,
                           extent_buffer, // Pasamos búfer v6
                           intent_buffer, // Pasamos búfer v7
                           canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v9 (v8 Estable).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v9(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {
  Timer timer;
  timer.step("start_v9_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v9 attr_cols(n_attributes, Bitset_v9(n_objects));
  ObjectRows_v9 obj_rows(n_objects, Bitset_v9(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents;
  DoubleArray intents;
  // initArray (de) usa calloc
  initVector(&extents, n_objects);
  initArray(&intents, n_attributes * 1000);

  // 3. *** OPTIMIZACIÓN V9: Crear búfer E/S (Intent) ***
  // (Usamos calloc para coincidir con initArray/freeArray)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V6: Crear búfer E/S (Extent)
  SparseVector extent_io_buffer;
  initVector(&extent_io_buffer, n_objects);

  // 5. Calcular el concepto inicial (top)
  Extent_v9 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v9 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v9_recursion");

  // 6. Iniciar la recursión (versión v9)
  inclose_fast_core_v9(-1, n_objects, n_attributes,
                       initial_extent, initial_intent,
                       attr_cols, obj_rows,
                       &extents, &intents,
                       extent_io_buffer, // Búfer v6
                       intent_io_buffer, // Búfer v7
                       &canonicity_tests, &all_att_intents);

  timer.step("end_v9_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer); // <-- ¡Importante! Usar free() para calloc()
  freeVector(&extent_io_buffer);

  // freeArray (de) usa free
  freeVector(&extents);
  freeArray(&intents);

  timer.step("end_v9_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents.used > 0) ? (intents.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 10 (FINAL): (v9 + E/S Extent a Granel) ---
// =============================================================================

// --- Definiciones de tipos para v10 ---
using Bitset_v10 = boost::dynamic_bitset<>;
using Extent_v10 = std::vector<int>;
using AttributeCols_v10 = std::vector<Bitset_v10>;
using ObjectRows_v10 = std::vector<Bitset_v10>;

// --- Helpers de E/S a Granel (v10) ---

// (Reutilizamos la versión estable v9 para Doubles)
// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }

// (Nuevos helpers v10 para Integers)
inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
  if (a->used + additional_size > a->size) {
    size_t newSize = (a->size + additional_size) * 1.5;
    if (newSize == 0) newSize = 1;
    int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
    if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
    a->array = tmp; a->size = newSize;
    for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
  }
}
inline void insertArray_bulk_int_v10(IntArray *a, int* buffer, size_t n) {
  ensureArray_int_v10(a, n);
  memcpy(&a->array[a->used], buffer, n * sizeof(int));
  a->used += n;
}

/**
 * @brief Core recursivo v10.
 * Reemplaza add_column() con E/S a granel para el extent.
 */
void inclose_fast_core_v10(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v10& extent,      // Concepto actual
                           Bitset_v10& intent,      // Concepto actual
                           const AttributeCols_v10& attr_cols,
                           const ObjectRows_v10& obj_rows,
                           SparseVector* extents_out, // Salida (dgCMatrix)
                           DoubleArray* intents_out, // Salida (Densa)
                           SparseVector& extent_buffer, // Búfer E/S v6
                           double* intent_buffer,       // Búfer E/S v7
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. *** OPTIMIZACIÓN V10: Guardar Extent (E/S a granel) ***

  // 1a. Llenar el búfer v6 (rápido, sin 'if (b.x > 0)')
  reinitVector(&extent_buffer);
  for(int obj : extent) {
    insertArray(&extent_buffer.i, obj);
    insertArray(&extent_buffer.x, 1.0);
  }

  // 1b. Volcar el búfer a 'extents_out' (reemplazo de add_column)
  // (Asumimos que extents_out es una dgCMatrix (p, i, x))

  size_t n_added = extent_buffer.i.used;

  // Volcar 'i' (índices de fila)
  insertArray_bulk_int_v10(&(extents_out->i), extent_buffer.i.array, n_added);

  // Volcar 'x' (valores)
  insertArray_bulk_double_v9(&(extents_out->x), extent_buffer.x.array, n_added);

  // Actualizar 'p' (punteros de columna)
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0); // p[0]
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added); // p[j+1]

  // 2. Optimización V9: Guardar Intent (E/S a granel)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v10 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v10 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Calcular child_extent (REUTILIZANDO 'child_extent')
    child_extent.clear();
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 6. Calcular child_intent (REUTILIZANDO 'child_intent')
    child_intent.set();
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 7. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 8. Recursión
    if (is_canonical) {
      inclose_fast_core_v10(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            extent_buffer, // Pasamos búfer v6
                            intent_buffer, // Pasamos búfer v7
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v10 (Final).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v10(NumericMatrix I,
                             StringVector attrs,
                             bool verbose = false) {
  Timer timer;
  timer.step("start_v10_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v10 attr_cols(n_attributes, Bitset_v10(n_objects));
  ObjectRows_v10 obj_rows(n_objects, Bitset_v10(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out; // Salida dgCMatrix
  DoubleArray intents_out;  // Salida Densa

  // (Estimación de pre-asignación)
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V6: Crear búfer E/S (Extent)
  SparseVector extent_io_buffer;
  initVector(&extent_io_buffer, n_objects);

  // 5. Calcular el concepto inicial (top)
  Extent_v10 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v10 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v10_recursion");

  // 6. Iniciar la recursión (versión v10)
  inclose_fast_core_v10(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        extent_io_buffer, // Búfer v6
                        intent_io_buffer, // Búfer v7
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v10_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer);
  freeVector(&extent_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_v10_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 11 (FINAL): (v9 + E/S Extent a Granel (No-Inline)) ---
// =============================================================================

// --- Definiciones de tipos para v11 ---
using Bitset_v11 = boost::dynamic_bitset<>;
using Extent_v11 = std::vector<int>;
using AttributeCols_v11 = std::vector<Bitset_v11>;
using ObjectRows_v11 = std::vector<Bitset_v11>;

// --- Helpers de E/S a Granel (v11) ---

// (Reutilizamos la versión estable v9 para Doubles)
// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }
//
// // (Reutilizamos helpers v10 para Integers)
// inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_int_v10(IntArray *a, int* buffer, size_t n) {
//   ensureArray_int_v10(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(int));
//   a->used += n;
// }

/**
 * @brief Helper v11. Reemplazo optimizado de add_column.
 * NO ES INLINE para mantener core_v11 pequeño (Caché L1i).
 */
void add_column_bulk(SparseVector *extents_out, SparseVector& extent_buffer) {

  size_t n_added = extent_buffer.i.used;
  if (n_added == 0) {
    // Manejar el caso de un extent vacío (aunque no debería guardarse)
    // Pero es seguro hacerlo.
    if (extents_out->p.used == 0) {
      insertArray(&(extents_out->p), 0);
    }
    int last_p = extents_out->p.array[extents_out->p.used - 1];
    insertArray(&(extents_out->p), last_p);
    return;
  }

  // Volcar 'i' (índices de fila)
  insertArray_bulk_int_v10(&(extents_out->i), extent_buffer.i.array, n_added);

  // Volcar 'x' (valores)
  insertArray_bulk_double_v9(&(extents_out->x), extent_buffer.x.array, n_added);

  // Actualizar 'p' (punteros de columna)
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0); // p[0]
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added); // p[j+1]
}


/**
 * @brief Core recursivo v11.
 * Llama a add_column_bulk (E/S v10)
 * Usa E/S a granel para Intent (v9)
 * Usa reutilización de memoria (v5)
 */
void inclose_fast_core_v11(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v11& extent,      // Concepto actual
                           Bitset_v11& intent,      // Concepto actual
                           const AttributeCols_v11& attr_cols,
                           const ObjectRows_v11& obj_rows,
                           SparseVector* extents_out, // Salida (dgCMatrix)
                           DoubleArray* intents_out, // Salida (Densa)
                           SparseVector& extent_buffer, // Búfer E/S v6
                           double* intent_buffer,       // Búfer E/S v7
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. *** OPTIMIZACIÓN V11: Guardar Extent (Llamada bulk no-inline) ***
  reinitVector(&extent_buffer);
  for(int obj : extent) {
    insertArray(&extent_buffer.i, obj);
    insertArray(&extent_buffer.x, 1.0);
  }
  add_column_bulk(extents_out, extent_buffer);

  // 2. Optimización V9: Guardar Intent (E/S a granel)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v11 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v11 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Calcular child_extent (REUTILIZANDO 'child_extent')
    child_extent.clear();
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 6. Calcular child_intent (REUTILIZANDO 'child_intent')
    child_intent.set();
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 7. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 8. Recursión
    if (is_canonical) {
      inclose_fast_core_v11(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            extent_buffer, // Pasamos búfer v6
                            intent_buffer, // Pasamos búfer v7
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v11 (Final).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v11(NumericMatrix I,
                             StringVector attrs,
                             bool verbose = false) {
  Timer timer;
  timer.step("start_v11_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v11 attr_cols(n_attributes, Bitset_v11(n_objects));
  ObjectRows_v11 obj_rows(n_objects, Bitset_v11(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out; // Salida dgCMatrix
  DoubleArray intents_out;  // Salida Densa

  // (Estimación de pre-asignación)
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V6: Crear búfer E/S (Extent)
  SparseVector extent_io_buffer;
  initVector(&extent_io_buffer, n_objects);

  // 5. Calcular el concepto inicial (top)
  Extent_v11 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v11 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v11_recursion");

  // 6. Iniciar la recursión (versión v11)
  inclose_fast_core_v11(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        extent_io_buffer, // Búfer v6
                        intent_io_buffer, // Búfer v7
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v11_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer);
  freeVector(&extent_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  // timer.step("end_v11_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 12 (LA APUESTA): (v11 + Fusión de Bucles) ---
// =============================================================================

// --- Definiciones de tipos para v12 ---
using Bitset_v12 = boost::dynamic_bitset<>;
using Extent_v12 = std::vector<int>;
using AttributeCols_v12 = std::vector<Bitset_v12>;
using ObjectRows_v12 = std::vector<Bitset_v12>;

// // --- Helpers de E/S a Granel (v11 estables) ---
// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }
// inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_int_v10(IntArray *a, int* buffer, size_t n) {
//   ensureArray_int_v10(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(int));
//   a->used += n;
// }
// void add_column_bulk(SparseVector *extents_out, SparseVector& extent_buffer) {
//   size_t n_added = extent_buffer.i.used;
//   if (extents_out->p.used == 0) {
//     insertArray(&(extents_out->p), 0);
//   }
//   int last_p = extents_out->p.array[extents_out->p.used - 1];
//   if (n_added == 0) {
//     insertArray(&(extents_out->p), last_p);
//     return;
//   }
//   insertArray_bulk_int_v10(&(extents_out->i), extent_buffer.i.array, n_added);
//   insertArray_bulk_double_v9(&(extents_out->x), extent_buffer.x.array, n_added);
//   insertArray(&(extents_out->p), last_p + n_added);
// }
// // --- Fin de Helpers ---


/**
 * @brief Core recursivo v12.
 * Fusiona los bucles de cálculo de extent e intent.
 */
void inclose_fast_core_v12(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v12& extent,      // Concepto actual
                           Bitset_v12& intent,      // Concepto actual
                           const AttributeCols_v12& attr_cols,
                           const ObjectRows_v12& obj_rows,
                           SparseVector* extents_out, // Salida (dgCMatrix)
                           DoubleArray* intents_out, // Salida (Densa)
                           SparseVector& extent_buffer, // Búfer E/S v6
                           double* intent_buffer,       // Búfer E/S v7
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. E/S Extent (v11)
  reinitVector(&extent_buffer);
  for(int obj : extent) {
    insertArray(&extent_buffer.i, obj);
    insertArray(&extent_buffer.x, 1.0);
  }
  add_column_bulk(extents_out, extent_buffer);

  // 2. E/S Intent (v9)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v12 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v12 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. *** OPTIMIZACIÓN V12: Fusión de Bucles ***

    // 5a. Limpiar buffers (v5)
    child_extent.clear();
    child_intent.set(); // Empezar con todo 1s

    // 5b. Bucle ÚNICO (O(|extent| * M/64))
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      // Comprobar si el objeto pertenece al hijo
      if (attr_j_bits.test(obj_idx)) {
        // (Era Bucle 1)
        child_extent.push_back(obj_idx);

        // (Era Bucle 2)
        child_intent &= obj_rows[obj_idx];
      }
    }

    // 5c. Comprobar si el resultado es vacío
    if (child_extent.empty()) continue;
    // (Ya no necesitamos comprobar child_intent.empty(),
    //  ya que es una consecuencia de child_extent.empty())

    // 6. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v12(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            extent_buffer, // Pasamos búfer v6
                            intent_buffer, // Pasamos búfer v7
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v12 (La Apuesta).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v12(NumericMatrix I,
                             StringVector attrs,
                             bool verbose = false) {
  Timer timer;
  timer.step("start_v12_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v12 attr_cols(n_attributes, Bitset_v12(n_objects));
  ObjectRows_v12 obj_rows(n_objects, Bitset_v12(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out; // Salida dgCMatrix
  DoubleArray intents_out;  // Salida Densa

  // (Estimación de pre-asignación)
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V6: Crear búfer E/S (Extent)
  SparseVector extent_io_buffer;
  initVector(&extent_io_buffer, n_objects);

  // 5. Calcular el concepto inicial (top)
  Extent_v12 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v12 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v12_recursion");

  // 6. Iniciar la recursión (versión v12)
  inclose_fast_core_v12(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        extent_io_buffer, // Búfer v6
                        intent_io_buffer, // Búfer v7
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v12_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer);
  freeVector(&extent_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  // timer.step("end_v12_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 13 (EL REGALO): (v12 + E/S Extent de Copia Cero) ---
// =============================================================================

// --- Definiciones de tipos para v13 ---
using Bitset_v13 = boost::dynamic_bitset<>;
using Extent_v13 = std::vector<int>;
using AttributeCols_v13 = std::vector<Bitset_v13>;
using ObjectRows_v13 = std::vector<Bitset_v13>;

// --- Helpers de E/S a Granel (v11 estables) ---
// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }
// inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// *** HELPER V13: memcpy directo desde std::vector<int> ***
inline void insertArray_bulk_int_v13(IntArray *a, const int* buffer, size_t n) {
  ensureArray_int_v10(a, n); // (la v10 es segura para ints)
  memcpy(&a->array[a->used], buffer, n * sizeof(int));
  a->used += n;
}
// --- Fin de Helpers ---


/**
 * @brief Core recursivo v13.
 * Elimina el 'extent_buffer' (v6) y escribe E/S a granel
 * directamente desde el std::vector (extent).
 */
void inclose_fast_core_v13(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v13& extent,      // Concepto actual
                           Bitset_v13& intent,      // Concepto actual
                           const AttributeCols_v13& attr_cols,
                           const ObjectRows_v13& obj_rows,
                           SparseVector* extents_out, // Salida (dgCMatrix)
                           DoubleArray* intents_out, // Salida (Densa)
                           double* intent_buffer,       // Búfer E/S v9
                           double* extent_x_buffer,     // Búfer E/S v13
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. *** OPTIMIZACIÓN V13: Guardar Extent (E/S de Copia Cero) ***
  size_t n_added = extent.size();

  if (n_added > 0) {
    // 1a. Volcar 'i' (memcpy directo desde std::vector)
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);

    // 1b. Volcar 'x' (usando el búfer v13)
    // (Llenar el búfer es más rápido que 'insertArray' N veces)
    for (size_t i = 0; i < n_added; ++i) {
      extent_x_buffer[i] = 1.0;
    }
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }

  // 1c. Actualizar 'p' (punteros de columna)
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0); // p[0]
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added); // p[j+1]

  // 2. E/S Intent (v9)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v13 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v13 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Fusión de Bucles (v12)
    child_extent.clear();
    child_intent.set();

    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
        child_intent &= obj_rows[obj_idx];
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v13(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            intent_buffer, // Pasamos búfer v9
                            extent_x_buffer, // Pasamos búfer v13
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v13 (El Regalo).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v13(NumericMatrix I,
                             StringVector attrs,
                             bool verbose = false) {
  Timer timer;
  timer.step("start_v13_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v13 attr_cols(n_attributes, Bitset_v13(n_objects));
  ObjectRows_v13 obj_rows(n_objects, Bitset_v13(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out; // Salida dgCMatrix
  DoubleArray intents_out;  // Salida Densa

  // (Estimación de pre-asignación)
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. *** OPTIMIZACIÓN V13: Crear búfer E/S (Extent X) ***
  // (Lo necesitamos porque el extent (std::vector<int>) no almacena 1.0)
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for extent_x_io_buffer");
  }

  // 5. Calcular el concepto inicial (top)
  Extent_v13 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v13 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v13_recursion");

  // 6. Iniciar la recursión (versión v13)
  inclose_fast_core_v13(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        intent_io_buffer, // Búfer v9
                        extent_x_io_buffer, // Búfer v13
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v13_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  // timer.step("end_v13_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 14 (EL REGALO): (v13 E/S + v11 Algoritmo) ---
// =============================================================================

// --- Definiciones de tipos para v14 ---
using Bitset_v14 = boost::dynamic_bitset<>;
using Extent_v14 = std::vector<int>;
using AttributeCols_v14 = std::vector<Bitset_v14>;
using ObjectRows_v14 = std::vector<Bitset_v14>;

// --- Helpers de E/S a Granel (v13 estables) ---
// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }
// inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_int_v13(IntArray *a, const int* buffer, size_t n) {
//   ensureArray_int_v10(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(int));
//   a->used += n;
// }
// --- Fin de Helpers ---


/**
 * @brief Core recursivo v14.
 * Des-fusiona los bucles (v11)
 * Usa E/S de Copia Cero (v13)
 */
void inclose_fast_core_v14(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v14& extent,      // Concepto actual
                           Bitset_v14& intent,      // Concepto actual
                           const AttributeCols_v14& attr_cols,
                           const ObjectRows_v14& obj_rows,
                           SparseVector* extents_out, // Salida (dgCMatrix)
                           DoubleArray* intents_out, // Salida (Densa)
                           double* intent_buffer,       // Búfer E/S v9
                           double* extent_x_buffer,     // Búfer E/S v13
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. E/S Extent (v13: Copia Cero)
  size_t n_added = extent.size();

  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    for (size_t i = 0; i < n_added; ++i) {
      extent_x_buffer[i] = 1.0;
    }
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }

  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v9)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v14 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v14 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. *** OPTIMIZACIÓN V14: Bucles Separados (v11) ***

    // 5a. Bucle 1: Calcular child_extent (O(|extent|))
    child_extent.clear();
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 5b. Bucle 2: Calcular child_intent (O(|child_extent| * M/64))
    child_intent.set();
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 6. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v14(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            intent_buffer, // Pasamos búfer v9
                            extent_x_buffer, // Pasamos búfer v13
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v14 (El Regalo).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v14(NumericMatrix I,
                             StringVector attrs,
                             bool verbose = false) {
  Timer timer;
  timer.step("start_v14_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v14 attr_cols(n_attributes, Bitset_v14(n_objects));
  ObjectRows_v14 obj_rows(n_objects, Bitset_v14(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out; // Salida dgCMatrix
  DoubleArray intents_out;  // Salida Densa

  // (Estimación de pre-asignación)
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V13: Crear búfer E/S (Extent X)
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for extent_x_io_buffer");
  }

  // 5. Calcular el concepto inicial (top)
  Extent_v14 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v14 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v14_recursion");

  // 6. Iniciar la recursión (versión v14)
  inclose_fast_core_v14(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        intent_io_buffer, // Búfer v9
                        extent_x_io_buffer, // Búfer v13
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v14_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  // timer.step("end_v14_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 15 (EL REGALO): (v14 + Búfer X Pre-llenado) ---
// =============================================================================

// --- Definiciones de tipos para v15 ---
using Bitset_v15 = boost::dynamic_bitset<>;
using Extent_v15 = std::vector<int>;
using AttributeCols_v15 = std::vector<Bitset_v15>;
using ObjectRows_v15 = std::vector<Bitset_v15>;

// --- Helpers de E/S a Granel (v13 estables) ---
// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }
// inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_int_v13(IntArray *a, const int* buffer, size_t n) {
//   ensureArray_int_v10(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(int));
//   a->used += n;
// }
// --- Fin de Helpers ---


/**
 * @brief Core recursivo v15.
 * Elimina el bucle de llenado de 1.0.
 */
void inclose_fast_core_v15(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v15& extent,      // Concepto actual
                           Bitset_v15& intent,      // Concepto actual
                           const AttributeCols_v15& attr_cols,
                           const ObjectRows_v15& obj_rows,
                           SparseVector* extents_out, // Salida (dgCMatrix)
                           DoubleArray* intents_out, // Salida (Densa)
                           double* intent_buffer,       // Búfer E/S v9
                           double* extent_x_buffer,     // Búfer E/S v13 (pre-llenado)
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. E/S Extent (v15: Copia Cero + X pre-llenado)
  size_t n_added = extent.size();

  if (n_added > 0) {
    // 1a. Volcar 'i' (memcpy directo desde std::vector)
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);

    // 1b. Volcar 'x' (memcpy desde el búfer pre-llenado)
    // (ELIMINADO: for (size_t i = 0; i < n_added; ++i) { ... })
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }

  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v9)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v15 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v15 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Bucles Separados (v14)

    // 5a. Bucle 1: Calcular child_extent (O(|extent|))
    child_extent.clear();
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 5b. Bucle 2: Calcular child_intent (O(|child_extent| * M/64))
    child_intent.set();
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 6. Test de Canonicidad (O(j) de v4)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v15(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            intent_buffer, // Pasamos búfer v9
                            extent_x_buffer, // Pasamos búfer v13
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v15 (El Regalo).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v15(NumericMatrix I,
                             StringVector attrs,
                             bool verbose = false) {
  Timer timer;
  timer.step("start_v15_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v15 attr_cols(n_attributes, Bitset_v15(n_objects));
  ObjectRows_v15 obj_rows(n_objects, Bitset_v15(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out; // Salida dgCMatrix
  DoubleArray intents_out;  // Salida Densa

  // (Estimación de pre-asignación)
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V13: Crear búfer E/S (Extent X)
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for extent_x_io_buffer");
  }

  // 5. *** OPTIMIZACIÓN V15: Pre-llenar el búfer X UNA VEZ ***
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 6. Calcular el concepto inicial (top)
  Extent_v15 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v15 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v15_recursion");

  // 7. Iniciar la recursión (versión v15)
  inclose_fast_core_v15(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        intent_io_buffer, // Búfer v9
                        extent_x_io_buffer, // Búfer v13
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v15_recursion");

  // 8. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 9. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  // timer.step("end_v15_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}


// =============================================================================
// --- VERSIÓN 16 (EL REGALO): (v15 + Canonicidad O(1)) ---
// =============================================================================

// --- Definiciones de tipos para v16 ---
using Bitset_v16 = boost::dynamic_bitset<>;
using Extent_v16 = std::vector<int>;
using AttributeCols_v16 = std::vector<Bitset_v16>;
using ObjectRows_v16 = std::vector<Bitset_v16>;

// --- Helpers de E/S a Granel (v13 estables) ---
// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }
// inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_int_v13(IntArray *a, const int* buffer, size_t n) {
//   ensureArray_int_v10(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(int));
//   a->used += n;
// }
// --- Fin de Helpers ---


/**
 * @brief Core recursivo v16.
 * Test de Canonicidad O(M/64) usando bitsets.
 */
void inclose_fast_core_v16(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v16& extent,      // Concepto actual
                           Bitset_v16& intent,      // Concepto actual
                           const AttributeCols_v16& attr_cols,
                           const ObjectRows_v16& obj_rows,
                           SparseVector* extents_out, // Salida (dgCMatrix)
                           DoubleArray* intents_out, // Salida (Densa)
                           double* intent_buffer,       // Búfer E/S v9
                           double* extent_x_buffer,     // Búfer E/S v13 (pre-llenado)
                           Bitset_v16& canonical_helper,  // Búfer v16
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v9)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent_v16 child_extent;
  child_extent.reserve(extent.size());
  Bitset_v16 child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Bucles Separados (v14)
    child_extent.clear();
    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
      }
    }
    if (child_extent.empty()) continue;

    child_intent.set();
    for (int obj_idx : child_extent) {
      child_intent &= obj_rows[obj_idx];
    }

    // 6. *** OPTIMIZACIÓN V16: Test de Canonicidad O(1) ***
    (*canonicity_tests) += 1.0;
    bool is_canonical;

    // 6a. Calcular bits nuevos: child_intent Y NO intent
    // (Usamos el búfer 'canonical_helper' (v16))
    canonical_helper = child_intent;
    canonical_helper.reset(j); // Ignoramos el bit 'j' (aún no es relevante)
    canonical_helper &= ~intent; // (child_intent \ intent)

    // 6b. Buscar el primer bit nuevo
    size_t k = canonical_helper.find_first();

    // 6c. Si el primer bit nuevo (k) es más pequeño que j, no es canónico
    if (k < j) {
      is_canonical = false;
    } else {
      is_canonical = true;
    }

    // 6d. (Optimización de conteo para all_att_intents)
    // Contamos los bits 'k < j' que NO estaban en 'intent'
    // (Esto es O(M/64), más rápido que el bucle O(j) de v15)
    canonical_helper = ~intent; // Bits que no están en el padre
    canonical_helper.resize(j); // Truncar en 'j'
    (*all_att_intents) += canonical_helper.count(); // Contar los candidatos

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v16(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            intent_buffer,
                            extent_x_buffer,
                            canonical_helper, // Pasamos el búfer v16
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v16 (El Regalo).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v16(NumericMatrix I,
                             StringVector attrs,
                             bool verbose = false) {
  Timer timer;
  timer.step("start_v16_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols_v16 attr_cols(n_attributes, Bitset_v16(n_objects));
  ObjectRows_v16 obj_rows(n_objects, Bitset_v16(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out; // Salida dgCMatrix
  DoubleArray intents_out;  // Salida Densa

  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V13: Crear búfer E/S (Extent X pre-llenado)
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for extent_x_io_buffer");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 5. *** OPTIMIZACIÓN V16: Crear búfer para Canonicidad ***
  Bitset_v16 canonical_helper(n_attributes);

  // 6. Calcular el concepto inicial (top)
  Extent_v16 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset_v16 initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v16_recursion");

  // 7. Iniciar la recursión (versión v16)
  inclose_fast_core_v16(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        intent_io_buffer,
                        extent_x_io_buffer,
                        canonical_helper, // Búfer v16
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v16_recursion");

  // 8. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 9. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  // (El timer.step("end_packaging") se omite, como pediste)

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 17 (SERIAL): (v13 Algoritmo + v15 E/S) ---
// =============================================================================

/**
 * @brief Core recursivo v17.
 * Algoritmo v13 (Fusión de Bucles)
 * E/S v15 (Búfer X Pre-llenado)
 */
void inclose_fast_core_v17_serial(int y,
                                  int n_objects,
                                  int n_attributes,
                                  Extent& extent,      // Concepto actual
                                  Bitset& intent,      // Concepto actual
                                  const AttributeCols& attr_cols,
                                  const ObjectRows& obj_rows,
                                  SparseVector* extents_out, // Salida (dgCMatrix)
                                  DoubleArray* intents_out, // Salida (Densa)
                                  double* intent_buffer,       // Búfer E/S v9
                                  double* extent_x_buffer,     // Búfer E/S v15 (pre-llenado)
                                  double* canonicity_tests,
                                  double* all_att_intents) {

  // 1. E/S Extent (v15: Copia Cero + X pre-llenado)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v9)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5)
  Extent child_extent;
  child_extent.reserve(extent.size());
  Bitset child_intent(n_attributes);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Fusión de Bucles (v13)
    child_extent.clear();
    child_intent.set();

    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
        child_intent &= obj_rows[obj_idx];
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (O(j) de v15)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v17_serial(j, n_objects, n_attributes,
                                   child_extent, child_intent,
                                   attr_cols, obj_rows,
                                   extents_out, intents_out,
                                   intent_buffer,
                                   extent_x_buffer,
                                   canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v17 (La Fusión Final).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v17(NumericMatrix I,
                               StringVector attrs,
                               bool verbose = false) {
  Timer timer;
  timer.step("start_v17_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales de bitset
  AttributeCols attr_cols(n_attributes, Bitset(n_objects));
  ObjectRows obj_rows(n_objects, Bitset(n_attributes));
  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Optimización V9: Crear búfer E/S (Intent)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  if (intent_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for intent_io_buffer");
  }

  // 4. Optimización V15: Crear búfer E/S (Extent X pre-llenado)
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for extent_x_io_buffer");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 5. Calcular el concepto inicial (top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset initial_intent(n_attributes);
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v17_recursion");

  // 6. Iniciar la recursión (versión v17)
  inclose_fast_core_v17_serial(-1, n_objects, n_attributes,
                               initial_extent, initial_intent,
                               attr_cols, obj_rows,
                               &extents_out, &intents_out,
                               intent_io_buffer,
                               extent_x_io_buffer,
                               &canonicity_tests, &all_att_intents);

  timer.step("end_v17_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// --- Helpers de E/S a Granel (v15 estables) ---
using Bitset_v18 = boost::dynamic_bitset<>; // Para Extents (N=2000)
using Extent_v18 = std::vector<int>;
using AttributeCols_v18 = std::vector<Bitset_v18>; // (N=2000)

// inline void ensureArray_double_v9(DoubleArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     double* tmp = (double *)realloc(a->array, newSize * sizeof(double));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (double)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_double_v9(DoubleArray *a, double* buffer, size_t n) {
//   ensureArray_double_v9(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(double));
//   a->used += n;
// }
// inline void ensureArray_int_v10(IntArray *a, size_t additional_size) {
//   if (a->used + additional_size > a->size) {
//     size_t newSize = (a->size + additional_size) * 1.5;
//     if (newSize == 0) newSize = 1;
//     int* tmp = (int *)realloc(a->array, newSize * sizeof(int));
//     if (tmp == NULL) { Rcpp::stop("Failed to realloc memory (int)"); }
//     a->array = tmp; a->size = newSize;
//     for (size_t i = a->used; i < a->size; i++) { a->array[i] = 0; }
//   }
// }
// inline void insertArray_bulk_int_v13(IntArray *a, const int* buffer, size_t n) {
//   ensureArray_int_v10(a, n);
//   memcpy(&a->array[a->used], buffer, n * sizeof(int));
//   a->used += n;
// }
// --- Fin de Helpers ---


// =============================================================================
// --- VERSIÓN 18 (EL REGALO GRANDE): (Fixed-Size Bitset) ---
// =============================================================================

// (Número máximo de atributos. 256 = 4 * 64)
#define MAX_ATTRIBUTES_V18 256
#define N_BLOCKS_V18 (MAX_ATTRIBUTES_V18 / 64)

/**
 * @brief (v18) El reemplazo de boost::dynamic_bitset para Intents.
 * Ultra-ligero, vive en la pila (stack).
 */
struct FixedBitsetM {
  uint64_t blocks[N_BLOCKS_V18];

  // Constructor (vacío)
  FixedBitsetM() {
    blocks[0] = 0; blocks[1] = 0; blocks[2] = 0;
  }

  // set() - Poner todo a 1
  inline void set() {
    blocks[0] = 0xFFFFFFFFFFFFFFFF;
    blocks[1] = 0xFFFFFFFFFFFFFFFF;
    blocks[2] = 0xFFFFFFFFFFFFFFFF;
  }

  // (El Asesino v17) Operador &= (Intersección)
  // Esto será inlined por el compilador -O3
  inline void operator&=(const FixedBitsetM& other) {
    blocks[0] &= other.blocks[0];
    blocks[1] &= other.blocks[1];
    blocks[2] &= other.blocks[2];
  }

  // (El Test Canónico v17) test(k)
  inline bool test(int k) const {
    int block_idx = k / 64;
    int bit_idx = k % 64;
    return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
  }

  // (Para E/S)
  inline void to_double_buffer(double* buffer, int n_attributes) const {
    for (int k = 0; k < n_attributes; ++k) {
      buffer[k] = test(k) ? 1.0 : 0.0;
    }
  }

  // (Para el setup de obj_rows)
  inline void set_bit(int k) {
    int block_idx = k / 64;
    int bit_idx = k % 64;
    blocks[block_idx] |= (1ULL << bit_idx);
  }
};

// (Definimos el nuevo tipo ObjectRows)
using ObjectRows_v18 = std::vector<FixedBitsetM>;


/**
 * @brief Core recursivo v18.
 * Usa FixedBitsetM para los intents.
 */
void inclose_fast_core_v18(int y,
                           int n_objects,
                           int n_attributes,
                           Extent_v18& extent,      // (std::vector)
                           FixedBitsetM& intent,    // (v18 struct)
                           const AttributeCols_v18& attr_cols, // (boost::bitset)
                           const ObjectRows_v18& obj_rows,    // (v18 vector<struct>)
                           SparseVector* extents_out,
                           DoubleArray* intents_out,
                           double* intent_buffer,
                           double* extent_x_buffer,
                           double* canonicity_tests,
                           double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v18)
  intent.to_double_buffer(intent_buffer, n_attributes);
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v5 + v18)
  Extent_v18 child_extent;
  child_extent.reserve(extent.size());
  FixedBitsetM child_intent; // <-- Vive en el Stack (¡Coste Cero!)

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Fusión de Bucles (v17)
    child_extent.clear();
    child_intent.set(); // (Resetea los 3 uint64_t a 1s)

    const auto& attr_j_bits = attr_cols[j]; // (boost::bitset)
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) { // (Test en boost)
        child_extent.push_back(obj_idx);

        // --- ¡LA OPERACIÓN v18! ---
        // (Inlined: 3 operaciones AND de 64 bits)
        child_intent &= obj_rows[obj_idx];
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (v18)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue; // (Test v18)
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) { // (Test v18)
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v18(j, n_objects, n_attributes,
                            child_extent, child_intent,
                            attr_cols, obj_rows,
                            extents_out, intents_out,
                            intent_buffer,
                            extent_x_buffer,
                            canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v18.
 */
// [[Rcpp::export]]
List InClose_binary_fast_v18(NumericMatrix I,
                                     StringVector attrs,
                                     bool verbose = false) {
  Timer timer;
  timer.step("start_v18_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (Comprobación de seguridad para v18)
  if (n_attributes > MAX_ATTRIBUTES_V18) {
    Rcpp::stop("Error: v18 solo soporta hasta %d atributos. (Actual: %d)",
               MAX_ATTRIBUTES_V18, n_attributes);
  }

  // 1. Construir representaciones duales
  // (attr_cols sigue siendo boost)
  AttributeCols_v18 attr_cols(n_attributes, Bitset_v18(n_objects));
  // (obj_rows es ahora el vector de structs v18)
  ObjectRows_v18 obj_rows(n_objects);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set_bit(c); // (Llamada v18)
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent_v18 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  FixedBitsetM initial_intent; // (v18 struct)
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx]; // (v18 &=)
  }

  timer.step("start_v18_recursion");

  // 5. Iniciar la recursión (versión v18)
  inclose_fast_core_v18(-1, n_objects, n_attributes,
                        initial_extent, initial_intent,
                        attr_cols, obj_rows,
                        &extents_out, &intents_out,
                        intent_io_buffer,
                        extent_x_io_buffer,
                        &canonicity_tests, &all_att_intents);

  timer.step("end_v18_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 20 (ESCALABLE): (v17 + Corrección de Memoria v5) ---
// =============================================================================

/**
 * @brief Core recursivo v20.
 * Reintroduce la optimización de memoria v5 (reutilización de child_intent)
 * en la arquitectura v17 (fusión de bucles + E/S v15).
 */
void inclose_fast_core_v20_scalable(int y,
                                    int n_objects,
                                    int n_attributes,
                                    Extent& extent,      // Concepto actual
                                    Bitset& intent,      // Concepto actual (Boost)
                                    const AttributeCols& attr_cols,
                                    const ObjectRows& obj_rows,
                                    SparseVector* extents_out,
                                    DoubleArray* intents_out,
                                    double* intent_buffer,
                                    double* extent_x_buffer,
                                    double* canonicity_tests,
                                    double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v9)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = intent.test(attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. *** OPTIMIZACIÓN V20 (Corrección v5) ***
  // Asignamos memoria para los hijos UNA VEZ, fuera del bucle.
  Extent child_extent;
  child_extent.reserve(extent.size());
  Bitset child_intent(n_attributes); // <-- Asignado en heap (escalable) UNA VEZ

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (intent.test(j)) continue;

    // 5. Fusión de Bucles (v17)
    child_extent.clear();
    child_intent.set(); // <-- REUTILIZAMOS la memoria (rápido)

    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);
        child_intent &= obj_rows[obj_idx]; // (Boost, escalable)
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (O(j) de v15)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (intent.test(k)) continue;
      (*all_att_intents) += 1.0;
      if (child_intent.test(k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v20_scalable(j, n_objects, n_attributes,
                                     child_extent, child_intent,
                                     attr_cols, obj_rows,
                                     extents_out, intents_out,
                                     intent_buffer,
                                     extent_x_buffer,
                                     canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v20 (Escalable).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v20(NumericMatrix I,
                                 StringVector attrs,
                                 bool verbose = false) {
  Timer timer;
  timer.step("start_v20_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // 1. Construir representaciones duales (Boost)
  AttributeCols attr_cols(n_attributes, Bitset(n_objects));
  ObjectRows obj_rows(n_objects);
  for(auto& row : obj_rows) {
    row.resize(n_attributes); // (Bug v17 corregido)
  }

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);
        obj_rows[r].set(c);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  Bitset initial_intent(n_attributes); // (Boost, escalable)
  initial_intent.set();
  for (int obj_idx : initial_extent) {
    initial_intent &= obj_rows[obj_idx];
  }

  timer.step("start_v20_recursion");

  // 6. Iniciar la recursión (versión v20)
  inclose_fast_core_v20_scalable(-1, n_objects, n_attributes,
                                 initial_extent, initial_intent,
                                 attr_cols, obj_rows,
                                 &extents_out, &intents_out,
                                 intent_io_buffer,
                                 extent_x_io_buffer,
                                 &canonicity_tests, &all_att_intents);

  timer.step("end_v20_recursion");

  // 7. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 8. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// --- Helpers de E/S a Granel (v15 estables) ---
using Bitset_N = boost::dynamic_bitset<>; // (Boost, para Extents N)
using Extent = std::vector<int>;
using AttributeCols = std::vector<Bitset_N>;

// =============================================================================
// --- VERSIÓN 21 (ESCALABLE + CACHÉ): (Bitset Plano Nativo) ---
// =============================================================================

// (v21) Array C++ plano para los Intents (Contiguo en Heap)
using ObjectRows_v21_flat = std::vector<uint64_t>;
// (v21) Acumulador de bits nativo (Contiguo en Heap)
using IntentAccumulator_v21 = std::vector<uint64_t>;

// (v21) Testeo nativo de bits (reemplazo de .test(k))
inline bool test_bit_native(const IntentAccumulator_v21& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}
// (v21) Testeo nativo de bits (para el 'intent' padre, que también es nativo)
inline bool test_bit_native_const(const std::vector<uint64_t>& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v21.
 * Usa arrays nativos (uint64_t) para TODOS los intents.
 */
void inclose_fast_core_v21_flat(int y,
                                int n_objects,
                                int n_attributes,
                                const size_t N_BLOCKS, // (v21) Num. bloques
                                Extent& extent,
                                IntentAccumulator_v21& intent, // (v21) Acumulador Nativo
                                const AttributeCols& attr_cols, // (Boost)
                                const ObjectRows_v21_flat& obj_rows_flat, // (v21) Datos Planos
                                SparseVector* extents_out,
                                DoubleArray* intents_out,
                                double* intent_buffer,
                                double* extent_x_buffer,
                                double* canonicity_tests,
                                double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native(intent, attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v21)
  Extent child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_v21 child_intent(N_BLOCKS); // (Heap, escalable) UNA VEZ

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native(intent, j)) continue;

    // 5. Fusión de Bucles (v17)
    child_extent.clear();
    // (v21 .set())
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    const auto& attr_j_bits = attr_cols[j]; // (Boost)
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);

        // --- ¡LA OPERACIÓN v21 (Cache-Friendly)! ---
        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS];
        for(size_t k = 0; k < N_BLOCKS; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (v21)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    for (int k = 0; k < j; k++) {
      if (test_bit_native(intent, k)) continue;
      (*all_att_intents) += 1.0;
      if (test_bit_native(child_intent, k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v21_flat(j, n_objects, n_attributes, N_BLOCKS,
                                 child_extent, child_intent,
                                 attr_cols, obj_rows_flat,
                                 extents_out, intents_out,
                                 intent_buffer,
                                 extent_x_buffer,
                                 canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v21 (Bitset Plano).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v21(NumericMatrix I,
                                    StringVector attrs,
                                    bool verbose = false) {
  Timer timer;
  timer.step("start_v21_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (v21) Cálculo de bloques
  const size_t N_BLOCKS = (n_attributes + 63) / 64;

  // 1. Construir representaciones duales
  // (attr_cols sigue siendo boost para N grande)
  AttributeCols attr_cols(n_attributes, Bitset_N(n_objects));

  // (obj_rows es ahora el vector plano v21)
  ObjectRows_v21_flat obj_rows_flat(n_objects * N_BLOCKS, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r); // (Boost)

        // (v21 set_bit nativo)
        int block_idx = c / 64;
        int bit_idx = c % 64;
        obj_rows_flat[r * N_BLOCKS + block_idx] |= (1ULL << bit_idx);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_v21 initial_intent(N_BLOCKS); // (v21 nativo)
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    // (v21 &=)
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS];
    for(size_t k = 0; k < N_BLOCKS; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_v21_recursion");

  // 5. Iniciar la recursión (versión v21)
  inclose_fast_core_v21_flat(-1, n_objects, n_attributes, N_BLOCKS,
                             initial_extent, initial_intent,
                             attr_cols, obj_rows_flat,
                             &extents_out, &intents_out,
                             intent_io_buffer,
                             extent_x_io_buffer,
                             &canonicity_tests, &all_att_intents);

  timer.step("end_v21_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 22 (NATIVA): (v21 + Transposición Total) ---
// =============================================================================

// (v22) Tipos Nativos
using Extent_v22 = std::vector<int>;
using AttributeCols_v22_flat = std::vector<uint64_t>;
using ObjectRows_v22_flat = std::vector<uint64_t>;
using IntentAccumulator_v22 = std::vector<uint64_t>;

// (v22) Testeo nativo de bits (M)
inline bool test_bit_native_M(const IntentAccumulator_v22& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (v22) Testeo nativo de bits (N)
inline bool test_bit_native_N(const AttributeCols_v22_flat& blocks,
                              int attr_j, int obj_idx, const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}


/**
 * @brief Core recursivo v22 (Totalmente Nativo).
 * Usa arrays nativos (uint64_t) para TODOS los intents Y extents.
 */
void inclose_fast_core_v22_native(int y,
                                  int n_objects,
                                  int n_attributes,
                                  const size_t N_BLOCKS_M, // (v22) Bloques de Intent
                                  const size_t N_BLOCKS_N, // (v22) Bloques de Extent
                                  Extent_v22& extent,
                                  IntentAccumulator_v22& intent,
                                  const AttributeCols_v22_flat& attr_cols_flat,
                                  const ObjectRows_v22_flat& obj_rows_flat,
                                  SparseVector* extents_out,
                                  DoubleArray* intents_out,
                                  double* intent_buffer,
                                  double* extent_x_buffer,
                                  double* canonicity_tests,
                                  double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M(intent, attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v21)
  Extent_v22 child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_v22 child_intent(N_BLOCKS_M);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M(intent, j)) continue;

    // 5. Fusión de Bucles (v22 - Totalmente Nativo)
    child_extent.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    for (int obj_idx : extent) {
      // (Test nativo v22)
      if (test_bit_native_N(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);

        // (Intersección nativa v22)
        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (v21)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    for (int k = 0; k < j; k++) {
      if (test_bit_native_M(intent, k)) continue;
      (*all_att_intents) += 1.0;
      if (test_bit_native_M(child_intent, k)) {
        is_canonical = false;
        break;
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v22_native(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                                   child_extent, child_intent,
                                   attr_cols_flat, obj_rows_flat,
                                   extents_out, intents_out,
                                   intent_buffer,
                                   extent_x_buffer,
                                   canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v22 (Totalmente Nativo).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v22(NumericMatrix I,
                               StringVector attrs,
                               bool verbose = false) {
  Timer timer;
  timer.step("start_v22_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (v22) Cálculo de bloques
  const size_t N_BLOCKS_M = (n_attributes + 63) / 64; // Para Intents
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;    // Para Extents

  // 1. Construir representaciones duales (NATIVAS)
  AttributeCols_v22_flat attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_v22_flat obj_rows_flat(n_objects * N_BLOCKS_M, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        // (v22 attr_cols set_bit)
        int block_idx_n = r / 64;
        int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);

        // (v22 obj_rows set_bit)
        int block_idx_m = c / 64;
        int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent_v22 initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_v22 initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_v22_recursion");

  // 5. Iniciar la recursión (versión v22)
  inclose_fast_core_v22_native(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                               initial_extent, initial_intent,
                               attr_cols_flat, obj_rows_flat,
                               &extents_out, &intents_out,
                               intent_io_buffer,
                               extent_x_io_buffer,
                               &canonicity_tests, &all_att_intents);

  timer.step("end_v22_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 23 (EL REGALO 2): (v21 + Canonicidad O(M/64)) ---
// =============================================================================

// (v23) Tipos Nativos (v21)
using ObjectRows_v23_flat = std::vector<uint64_t>;
using IntentAccumulator_v23 = std::vector<uint64_t>;

/**
 * @brief Core recursivo v23 (Canonicidad Nativa).
 * Usa arrays nativos (uint64_t) para TODOS los intents.
 */
void inclose_fast_core_v23_native_canon(int y,
                                        int n_objects,
                                        int n_attributes,
                                        const size_t N_BLOCKS_M, // (v21) Bloques de Intent
                                        Extent& extent,
                                        IntentAccumulator_v23& intent, // (v21) Acumulador Nativo
                                        const AttributeCols& attr_cols, // (Boost)
                                        const ObjectRows_v23_flat& obj_rows_flat, // (v21) Datos Planos
                                        SparseVector* extents_out,
                                        DoubleArray* intents_out,
                                        double* intent_buffer,
                                        double* extent_x_buffer,
                                        double* canonicity_tests,
                                        double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M(intent, attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v21)
  Extent child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_v23 child_intent(N_BLOCKS_M);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M(intent, j)) continue;

    // 5. Fusión de Bucles (v21 - Cache-Friendly)
    child_extent.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    const auto& attr_j_bits = attr_cols[j];
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);

        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    if (child_extent.empty()) continue;

    // 6. *** OPTIMIZACIÓN V23: Test de Canonicidad O(M/64) ***
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;

    // (Calculamos dónde está 'j' en los bloques)
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    // (Bucle 1: Bloques ANTES de 'j')
    for (int b = 0; b < j_block_idx; b++) {
      // (Calcula bits nuevos: child Y NO parent)
      uint64_t new_bits = child_intent[b] & (~intent[b]);
      if (new_bits != 0) {
        // (Si hay CUALQUIER bit nuevo aquí, es < j)
        is_canonical = false;
        break;
      }
    }

    // (Bucle 2: El bloque DONDE está 'j')
    if (is_canonical) {
      // (Calcula bits nuevos)
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        // (Crea una máscara para bits < j)
        // (1ULL << j_bit_idx) -> 00...1...00
        // (... - 1)          -> 00...0...11 (todos los bits < j)
        uint64_t mask = (1ULL << j_bit_idx) - 1;

        // (Comprueba si hay bits nuevos < j)
        if ((new_bits & mask) != 0) {
          is_canonical = false;
        }
      }
    }

    // (Cálculo de all_att_intents (rápido))
    // (Esto es O(M/64), más rápido que el bucle O(j) de v15)
    for (size_t b = 0; b < N_BLOCKS_M; ++b) {
      uint64_t candidates = ~intent[b];
      if (b == j_block_idx) {
        // (Máscara para bits < j)
        uint64_t mask = (1ULL << j_bit_idx) - 1;
        candidates &= mask;
      } else if (b > j_block_idx) {
        candidates = 0; // (No contamos k > j)
      }
      (*all_att_intents) += __builtin_popcountll(candidates);
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v23_native_canon(j, n_objects, n_attributes, N_BLOCKS_M,
                                         child_extent, child_intent,
                                         attr_cols, obj_rows_flat,
                                         extents_out, intents_out,
                                         intent_buffer,
                                         extent_x_buffer,
                                         canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v23 (Canonicidad Nativa).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v23(NumericMatrix I,
                                     StringVector attrs,
                                     bool verbose = false) {
  Timer timer;
  timer.step("start_v23_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (v21) Cálculo de bloques
  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;

  // 1. Construir representaciones duales
  AttributeCols attr_cols(n_attributes, Bitset_N(n_objects));
  ObjectRows_v23_flat obj_rows_flat(n_objects * N_BLOCKS_M, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);

        int block_idx_m = c / 64;
        int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_v23 initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_v23_recursion");

  // 5. Iniciar la recursión (versión v23)
  inclose_fast_core_v23_native_canon(-1, n_objects, n_attributes, N_BLOCKS_M,
                                     initial_extent, initial_intent,
                                     attr_cols, obj_rows_flat,
                                     &extents_out, &intents_out,
                                     intent_io_buffer,
                                     extent_x_io_buffer,
                                     &canonicity_tests, &all_att_intents);

  timer.step("end_v23_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}


// =============================================================================
// --- VERSIÓN 24 (HÍBRIDA NATIVA): (InClose + CbO) ---
// =============================================================================

// (v24) Tipos Nativos
using Extent_v24 = std::vector<int>;
using AttributeCols_v24_flat = std::vector<uint64_t>;
using ObjectRows_v24_flat = std::vector<uint64_t>;
using IntentAccumulator_v24 = std::vector<uint64_t>;
using ExtentAccumulator_v24 = std::vector<uint64_t>; // (El CbO necesita esto)

// (v24) Testeo nativo de bits (M) (RENOMBRADO)
inline bool test_bit_native_M_v24(const IntentAccumulator_v24& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (v24) Testeo nativo de bits (N) (RENOMBRADO)
inline bool test_bit_native_N_v24(const AttributeCols_v24_flat& blocks,
                                  int attr_j, int obj_idx, const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}
// (v24) Testeo nativo de bits (N) (para el Acumulador) (RENOMBRADO)
inline bool test_bit_native_N_acc_v24(const ExtentAccumulator_v24& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (v24) Declaración adelantada (para recursión mutua)
void inclose_fast_core_v24_hybrid(int y, int g,
                                  int n_objects, int n_attributes,
                                  const size_t N_BLOCKS_M, const size_t N_BLOCKS_N,
                                  Extent_v24& extent_vec,
                                  IntentAccumulator_v24& intent,
                                  ExtentAccumulator_v24& extent,
                                  const AttributeCols_v24_flat& attr_cols_flat,
                                  const ObjectRows_v24_flat& obj_rows_flat,
                                  SparseVector* extents_out,
                                  DoubleArray* intents_out,
                                  double* intent_buffer,
                                  double* extent_x_buffer,
                                  double* canonicity_tests,
                                  double* all_att_intents,
                                  double* cbo_tests);


// =============================================================
// --- (A) NÚCLEO IN-CLOSE (v24) ---
// =============================================================
void inclose_fast_core_v24_INCLOSE(int y, int g,
                                   int n_objects, int n_attributes,
                                   const size_t N_BLOCKS_M, const size_t N_BLOCKS_N,
                                   Extent_v24& extent_vec,
                                   IntentAccumulator_v24& intent,
                                   ExtentAccumulator_v24& extent,
                                   const AttributeCols_v24_flat& attr_cols_flat,
                                   const ObjectRows_v24_flat& obj_rows_flat,
                                   SparseVector* extents_out,
                                   DoubleArray* intents_out,
                                   double* intent_buffer,
                                   double* extent_x_buffer,
                                   double* canonicity_tests,
                                   double* all_att_intents,
                                   double* cbo_tests) {

  Extent_v24 child_extent_vec;
  child_extent_vec.reserve(extent_vec.size());
  IntentAccumulator_v24 child_intent(N_BLOCKS_M);

  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_v24(intent, j)) continue; // (v24)

    child_extent_vec.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    for (int obj_idx : extent_vec) {
      if (test_bit_native_N_v24(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) { // (v24)
        child_extent_vec.push_back(obj_idx);
        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    if (child_extent_vec.empty()) continue;

    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;
    for (int b = 0; b < j_block_idx; b++) {
      uint64_t new_bits = child_intent[b] & (~intent[b]);
      if (new_bits != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (1ULL << j_bit_idx) - 1;
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }
    for (size_t b = 0; b < N_BLOCKS_M; ++b) {
      uint64_t candidates = ~intent[b];
      if (b == j_block_idx) { candidates &= ((1ULL << j_bit_idx) - 1); }
      else if (b > j_block_idx) { candidates = 0; }
      (*all_att_intents) += __builtin_popcountll(candidates);
    }

    if (is_canonical) {
      ExtentAccumulator_v24 child_extent(N_BLOCKS_N, 0);
      for(int obj_idx : child_extent_vec) {
        int block_idx_n = obj_idx / 64;
        int bit_idx_n = obj_idx % 64;
        child_extent[block_idx_n] |= (1ULL << bit_idx_n);
      }

      inclose_fast_core_v24_hybrid(j, g,
                                   n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                                   child_extent_vec, child_intent, child_extent,
                                   attr_cols_flat, obj_rows_flat,
                                   extents_out, intents_out,
                                   intent_buffer, extent_x_buffer,
                                   canonicity_tests, all_att_intents, cbo_tests);
    }
  }
}

// =============================================================
// --- (B) NÚCLEO FAST-CBO (v24) ---
// =============================================================
void inclose_fast_core_v24_CBO(int y, int g,
                               int n_objects, int n_attributes,
                               const size_t N_BLOCKS_M, const size_t N_BLOCKS_N,
                               Extent_v24& extent_vec,
                               IntentAccumulator_v24& intent,
                               ExtentAccumulator_v24& extent,
                               const AttributeCols_v24_flat& attr_cols_flat,
                               const ObjectRows_v24_flat& obj_rows_flat,
                               SparseVector* extents_out,
                               DoubleArray* intents_out,
                               double* intent_buffer,
                               double* extent_x_buffer,
                               double* canonicity_tests,
                               double* all_att_intents,
                               double* cbo_tests) {

  ExtentAccumulator_v24 child_extent(N_BLOCKS_N);
  IntentAccumulator_v24 child_intent(N_BLOCKS_M);

  for (int i = g + 1; i < n_objects; i++) {
    if (test_bit_native_N_acc_v24(extent, i)) continue; // (v24)

    bool is_equal = true;
    const uint64_t* row_ptr = &obj_rows_flat[i * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      child_intent[k] = intent[k] & row_ptr[k];
      if (child_intent[k] != intent[k]) is_equal = false;
    }
    if (is_equal) continue;

    std::fill(child_extent.begin(), child_extent.end(), 0xFFFFFFFFFFFFFFFF);
    for(size_t j = 0; j < n_attributes; ++j) {
      if (test_bit_native_M_v24(child_intent, j)) { // (v24)
        const uint64_t* col_ptr = &attr_cols_flat[j * N_BLOCKS_N];
        for(size_t k = 0; k < N_BLOCKS_N; ++k) {
          child_extent[k] &= col_ptr[k];
        }
      }
    }

    (*cbo_tests) += 1.0;

    size_t k = n_objects;
    for(size_t b = 0; b < N_BLOCKS_N; ++b) {
      uint64_t new_bits = child_extent[b] & (~extent[b]);
      if (new_bits != 0) {
        k = (b * 64) + __builtin_ctzll(new_bits);
        break;
      }
    }

    if (k == i) {
      Extent_v24 child_extent_vec;
      child_extent_vec.reserve(n_objects);
      for(size_t obj=i; obj < n_objects; ++obj) {
        if (test_bit_native_N_acc_v24(child_extent, obj)) { // (v24)
          child_extent_vec.push_back(obj);
        }
      }

      inclose_fast_core_v24_hybrid(y, i,
                                   n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                                   child_extent_vec, child_intent, child_extent,
                                   attr_cols_flat, obj_rows_flat,
                                   extents_out, intents_out,
                                   intent_buffer, extent_x_buffer,
                                   canonicity_tests, all_att_intents, cbo_tests);
    }
  }
}


// =============================================================
// --- (C) EL NÚCLEO HÍBRIDO v24 (Elige la Estrategia) ---
// =============================================================
void inclose_fast_core_v24_hybrid(int y, int g,
                                  int n_objects, int n_attributes,
                                  const size_t N_BLOCKS_M, const size_t N_BLOCKS_N,
                                  Extent_v24& extent_vec,
                                  IntentAccumulator_v24& intent,
                                  ExtentAccumulator_v24& extent,
                                  const AttributeCols_v24_flat& attr_cols_flat,
                                  const ObjectRows_v24_flat& obj_rows_flat,
                                  SparseVector* extents_out,
                                  DoubleArray* intents_out,
                                  double* intent_buffer,
                                  double* extent_x_buffer,
                                  double* canonicity_tests,
                                  double* all_att_intents,
                                  double* cbo_tests) {

  // 1. E/S (Guardamos el concepto encontrado)
  size_t n_added = extent_vec.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent_vec.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M_v24(intent, attr) ? 1.0 : 0.0; // (v24)
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 2. LA DECISIÓN HÍBRIDA
  size_t intent_size = 0;
  for(size_t k = 0; k < N_BLOCKS_M; ++k) {
    intent_size += __builtin_popcountll(intent[k]);
  }

  double cost_inclose = (double)extent_vec.size() * (double)n_attributes;
  double cost_cbo = (double)intent_size * (double)n_objects;

  if (cost_inclose <= cost_cbo) {
    // --- ESTRATEGIA IN-CLOSE (v23) ---
    inclose_fast_core_v24_INCLOSE(y, g,
                                  n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                                  extent_vec, intent, extent,
                                  attr_cols_flat, obj_rows_flat,
                                  extents_out, intents_out,
                                  intent_buffer, extent_x_buffer,
                                  canonicity_tests, all_att_intents, cbo_tests);
  } else {
    // --- ESTRATEGIA CBO (v18) ---
    inclose_fast_core_v24_CBO(y, g,
                              n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                              extent_vec, intent, extent,
                              attr_cols_flat, obj_rows_flat,
                              extents_out, intents_out,
                              intent_buffer, extent_x_buffer,
                              canonicity_tests, all_att_intents, cbo_tests);
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v24 (Híbrido Nativo).
 */
// [[Rcpp::export]]
List InClose_binary_v24(NumericMatrix I,
                                      StringVector attrs,
                                      bool verbose = false) {
  Timer timer;
  timer.step("start_v24_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;

  // 1. Construir representaciones duales (NATIVAS)
  AttributeCols_v24_flat attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_v24_flat obj_rows_flat(n_objects * N_BLOCKS_M, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  double cbo_tests = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent_v24 initial_extent_vec; // (Disperso)
  initial_extent_vec.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent_vec.push_back(i);

  ExtentAccumulator_v24 initial_extent(N_BLOCKS_N); // (Denso)
  std::fill(initial_extent.begin(), initial_extent.end(), 0xFFFFFFFFFFFFFFFF);

  IntentAccumulator_v24 initial_intent(N_BLOCKS_M); // (Denso)
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent_vec) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  std::fill(initial_extent.begin(), initial_extent.end(), 0xFFFFFFFFFFFFFFFF);
  for(size_t j = 0; j < n_attributes; ++j) {
    if (test_bit_native_M_v24(initial_intent, j)) { // (v24)
      const uint64_t* col_ptr = &attr_cols_flat[j * N_BLOCKS_N];
      for(size_t k = 0; k < N_BLOCKS_N; ++k) {
        initial_extent[k] &= col_ptr[k];
      }
    }
  }

  initial_extent_vec.clear();
  for(size_t obj=0; obj < n_objects; ++obj) {
    if (test_bit_native_N_acc_v24(initial_extent, obj)) { // (v24)
      initial_extent_vec.push_back(obj);
    }
  }

  timer.step("start_v24_recursion");

  // 5. Iniciar la recursión (versión v24)
  inclose_fast_core_v24_hybrid(-1, -1, // (y, g)
                               n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                               initial_extent_vec, initial_intent, initial_extent,
                               attr_cols_flat, obj_rows_flat,
                               &extents_out, &intents_out,
                               intent_io_buffer,
                               extent_x_io_buffer,
                               &canonicity_tests, &all_att_intents, &cbo_tests);

  timer.step("end_v24_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["cbo_tests"] = cbo_tests,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 25 (SUSCRIPCIÓN): (v23 + Extent Denso Nativo) (CORREGIDO) ---
// =============================================================================

// (v25) Tipos Nativos
using Extent_v25_disperso = std::vector<int>;
using AttributeCols_v25_flat = std::vector<uint64_t>;
using ObjectRows_v25_flat = std::vector<uint64_t>;
using IntentAccumulator_v25 = std::vector<uint64_t>;
using ExtentAccumulator_v25 = std::vector<uint64_t>;

// (v25) Testeo nativo de bits (M) (RENOMBRADO)
inline bool test_bit_native_M_v25(const IntentAccumulator_v25& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (v25) Testeo nativo de bits (N) (para el Acumulador) (RENOMBRADO)
inline bool test_bit_native_N_acc_v25(const ExtentAccumulator_v25& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v25 (Totalmente Nativo y Denso).
 */
void inclose_fast_core_v25_native(int y,
                                  int n_objects,
                                  int n_attributes,
                                  const size_t N_BLOCKS_M,
                                  const size_t N_BLOCKS_N,
                                  ExtentAccumulator_v25& extent,
                                  IntentAccumulator_v25& intent,
                                  const AttributeCols_v25_flat& attr_cols_flat,
                                  const ObjectRows_v25_flat& obj_rows_flat,
                                  SparseVector* extents_out,
                                  DoubleArray* intents_out,
                                  double* intent_buffer,
                                  double* extent_x_buffer,
                                  Extent_v25_disperso& extent_io_buffer,
                                  double* canonicity_tests,
                                  double* all_att_intents) {

  // 1. E/S Extent (v25: Convertir Denso a Disperso para E/S)
  extent_io_buffer.clear();
  size_t n_added = 0;
  for (int obj_idx = 0; obj_idx < n_objects; ++obj_idx) {
    if (test_bit_native_N_acc_v25(extent, obj_idx)) { // (v25)
      extent_io_buffer.push_back(obj_idx);
      n_added++;
    }
  }

  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent_io_buffer.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M_v25(intent, attr) ? 1.0 : 0.0; // (v25)
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v21)
  IntentAccumulator_v25 child_intent(N_BLOCKS_M);
  ExtentAccumulator_v25 child_extent(N_BLOCKS_N);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_v25(intent, j)) continue; // (v25)

    // 5. Bucle Denso/Nativo (O(N/64))
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    const uint64_t* attr_j_ptr = &attr_cols_flat[j * N_BLOCKS_N];

    bool is_empty = true;
    for(size_t k = 0; k < N_BLOCKS_N; ++k) {
      child_extent[k] = extent[k] & attr_j_ptr[k];
      if (child_extent[k] != 0) is_empty = false;
    }

    if (is_empty) continue;

    for(size_t obj_idx = 0; obj_idx < n_objects; ++obj_idx) {
      if (test_bit_native_N_acc_v25(child_extent, obj_idx)) { // (v25)
        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    // 6. Test de Canonicidad (v23)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;
    for (int b = 0; b < j_block_idx; b++) {
      uint64_t new_bits = child_intent[b] & (~intent[b]);
      if (new_bits != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (1ULL << j_bit_idx) - 1;
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }
    for (size_t b = 0; b < N_BLOCKS_M; ++b) {
      uint64_t candidates = ~intent[b];
      if (b == j_block_idx) { candidates &= ((1ULL << j_bit_idx) - 1); }
      else if (b > j_block_idx) { candidates = 0; }
      (*all_att_intents) += __builtin_popcountll(candidates);
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v25_native(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                                   child_extent, child_intent,
                                   attr_cols_flat, obj_rows_flat,
                                   extents_out, intents_out,
                                   intent_buffer,
                                   extent_x_buffer,
                                   extent_io_buffer,
                                   canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v25 (Totalmente Denso).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v25(NumericMatrix I,
                                     StringVector attrs,
                                     bool verbose = false) {
  Timer timer;
  timer.step("start_v25_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;

  // 1. Construir representaciones duales (NATIVAS)
  AttributeCols_v25_flat attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_v25_flat obj_rows_flat(n_objects * N_BLOCKS_M, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15 + v25)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }
  Extent_v25_disperso extent_io_buffer;
  extent_io_buffer.reserve(n_objects);

  // 4. Calcular el concepto inicial (Top)
  ExtentAccumulator_v25 initial_extent(N_BLOCKS_N);
  std::fill(initial_extent.begin(), initial_extent.end(), 0xFFFFFFFFFFFFFFFF);
  IntentAccumulator_v25 initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for(size_t obj_idx = 0; obj_idx < n_objects; ++obj_idx) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  std::fill(initial_extent.begin(), initial_extent.end(), 0xFFFFFFFFFFFFFFFF);
  for(size_t j = 0; j < n_attributes; ++j) {
    if (test_bit_native_M_v25(initial_intent, j)) { // (v25)
      const uint64_t* col_ptr = &attr_cols_flat[j * N_BLOCKS_N];
      for(size_t k = 0; k < N_BLOCKS_N; ++k) {
        initial_extent[k] &= col_ptr[k];
      }
    }
  }

  timer.step("start_v25_recursion");

  // 5. Iniciar la recursión (versión v25)
  inclose_fast_core_v25_native(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                               initial_extent, initial_intent,
                               attr_cols_flat, obj_rows_flat,
                               &extents_out, &intents_out,
                               intent_io_buffer,
                               extent_x_io_buffer,
                               extent_io_buffer,
                               &canonicity_tests, &all_att_intents);

  timer.step("end_v25_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 27 (PRO): (v23 + Transposición Total) ---
// =============================================================================

// (v27) Tipos Nativos
using Extent_v27 = std::vector<int>; // (Disperso)
using AttributeCols_v27_flat = std::vector<uint64_t>;
using ObjectRows_v27_flat = std::vector<uint64_t>;
using IntentAccumulator_v27 = std::vector<uint64_t>;

// (v27) Testeo nativo de bits (M)
inline bool test_bit_native_M_v27(const IntentAccumulator_v27& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (v27) Testeo nativo de bits (N)
inline bool test_bit_native_N_v27(const AttributeCols_v27_flat& blocks,
                                  int attr_j, int obj_idx, const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v27 (Totalmente Nativo, Algoritmo v23).
 */
void inclose_fast_core_v27_native(int y,
                                  int n_objects,
                                  int n_attributes,
                                  const size_t N_BLOCKS_M, // (v21)
                                  const size_t N_BLOCKS_N, // (v22)
                                  Extent_v27& extent, // (Disperso v23)
                                  IntentAccumulator_v27& intent, // (Nativo Denso v21)
                                  const AttributeCols_v27_flat& attr_cols_flat, // (Nativo Denso v22)
                                  const ObjectRows_v27_flat& obj_rows_flat, // (Nativo Denso v21)
                                  SparseVector* extents_out,
                                  DoubleArray* intents_out,
                                  double* intent_buffer,
                                  double* extent_x_buffer,
                                  double* canonicity_tests,
                                  double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M_v27(intent, attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v21)
  Extent_v27 child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_v27 child_intent(N_BLOCKS_M);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_v27(intent, j)) continue;

    // 5. Fusión de Bucles (v27 - Totalmente Nativo)
    child_extent.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    for (int obj_idx : extent) {
      // --- ¡OPTIMIZADO v27! (Test nativo) ---
      if (test_bit_native_N_v27(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);

        // --- (OPTIMIZADO v23) ---
        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (v23)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;
    for (int b = 0; b < j_block_idx; b++) {
      uint64_t new_bits = child_intent[b] & (~intent[b]);
      if (new_bits != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (1ULL << j_bit_idx) - 1;
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }
    for (size_t b = 0; b < N_BLOCKS_M; ++b) {
      uint64_t candidates = ~intent[b];
      if (b == j_block_idx) { candidates &= ((1ULL << j_bit_idx) - 1); }
      else if (b > j_block_idx) { candidates = 0; }
      (*all_att_intents) += __builtin_popcountll(candidates);
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v27_native(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                                   child_extent, child_intent,
                                   attr_cols_flat, obj_rows_flat,
                                   extents_out, intents_out,
                                   intent_buffer,
                                   extent_x_buffer,
                                   canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v27 (Pro).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v27(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {
  Timer timer;
  timer.step("start_v27_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (v22) Cálculo de bloques
  const size_t N_BLOCKS_M = (n_attributes + 63) / 64; // Para Intents
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;    // Para Extents

  // 1. Construir representaciones duales (NATIVAS)
  AttributeCols_v27_flat attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_v27_flat obj_rows_flat(n_objects * N_BLOCKS_M, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent_v27 initial_extent; // (Disperso)
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_v27 initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_v27_recursion");

  // 5. Iniciar la recursión (versión v27)
  inclose_fast_core_v27_native(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                               initial_extent, initial_intent,
                               attr_cols_flat, obj_rows_flat,
                               &extents_out, &intents_out,
                               intent_io_buffer,
                               extent_x_io_buffer,
                               &canonicity_tests, &all_att_intents);

  timer.step("end_v27_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 28 (PRO): (v23 - Contador de Diagnóstico) ---
// =============================================================================

// (v28) Tipos Nativos (v21)
using ObjectRows_v28_flat = std::vector<uint64_t>;
using IntentAccumulator_v28 = std::vector<uint64_t>;

// (v28) Testeo nativo de bits (M)
inline bool test_bit_native_M_v28(const IntentAccumulator_v28& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v28 (v23 sin contadores).
 */
void inclose_fast_core_v28_pro(int y,
                               int n_objects,
                               int n_attributes,
                               const size_t N_BLOCKS_M,
                               Extent& extent,
                               IntentAccumulator_v28& intent,
                               const AttributeCols& attr_cols, // (Boost)
                               const ObjectRows_v28_flat& obj_rows_flat,
                               SparseVector* extents_out,
                               DoubleArray* intents_out,
                               double* intent_buffer,
                               double* extent_x_buffer,
                               double* canonicity_tests,
                               double* all_att_intents) { // (Sigue aquí, pero no se usa)

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M_v28(intent, attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v21)
  Extent child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_v28 child_intent(N_BLOCKS_M);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_v28(intent, j)) continue;

    // 5. Fusión de Bucles (v23)
    child_extent.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    const auto& attr_j_bits = attr_cols[j]; // (Boost)
    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) { // (Boost.test())
        child_extent.push_back(obj_idx);

        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (v23)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;
    for (int b = 0; b < j_block_idx; b++) {
      uint64_t new_bits = child_intent[b] & (~intent[b]);
      if (new_bits != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (1ULL << j_bit_idx) - 1;
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }

    // 7. *** OPTIMIZACIÓN V28: CONTADOR ELIMINADO ***
    // (Bucle de all_att_intents eliminado para velocidad)
    // for (size_t b = 0; b < N_BLOCKS_M; ++b) {
    //     ...
    //     (*all_att_intents) += __builtin_popcountll(candidates);
    // }

    // 8. Recursión
    if (is_canonical) {
      inclose_fast_core_v28_pro(j, n_objects, n_attributes, N_BLOCKS_M,
                                child_extent, child_intent,
                                attr_cols, obj_rows_flat,
                                extents_out, intents_out,
                                intent_buffer,
                                extent_x_buffer,
                                canonicity_tests, all_att_intents); // (Pasamos el puntero)
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v28 (Pro).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v28(NumericMatrix I,
                            StringVector attrs,
                            bool verbose = false) {
  Timer timer;
  timer.step("start_v28_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;

  // 1. Construir representaciones duales (v23)
  AttributeCols attr_cols(n_attributes, Bitset_N(n_objects)); // (Boost)
  ObjectRows_v28_flat obj_rows_flat(n_objects * N_BLOCKS_M, 0); // (Nativa)

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);

        int block_idx_m = c / 64;
        int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0; // (Ya no se calculará)
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_v28 initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_v28_recursion");

  // 5. Iniciar la recursión (versión v28)
  inclose_fast_core_v28_pro(-1, n_objects, n_attributes, N_BLOCKS_M,
                            initial_extent, initial_intent,
                            attr_cols, obj_rows_flat,
                            &extents_out, &intents_out,
                            intent_io_buffer,
                            extent_x_io_buffer,
                            &canonicity_tests, &all_att_intents);

  timer.step("end_v28_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0, // (Sacrificado)
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 29 (PRO): (v23 + Prefetching) ---
// =============================================================================

// (v29) Tipos Nativos (v21)
using ObjectRows_v29_flat = std::vector<uint64_t>;
using IntentAccumulator_v29 = std::vector<uint64_t>;

// (v29) Testeo nativo de bits (M)
inline bool test_bit_native_M_v29(const IntentAccumulator_v29& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v29 (Prefetching).
 */
void inclose_fast_core_v29_prefetch(int y,
                                    int n_objects,
                                    int n_attributes,
                                    const size_t N_BLOCKS_M,
                                    Extent& extent,
                                    IntentAccumulator_v29& intent,
                                    const AttributeCols& attr_cols, // (Boost)
                                    const ObjectRows_v29_flat& obj_rows_flat,
                                    SparseVector* extents_out,
                                    DoubleArray* intents_out,
                                    double* intent_buffer,
                                    double* extent_x_buffer,
                                    double* canonicity_tests,
                                    double* all_att_intents) {

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M_v29(intent, attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v21)
  Extent child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_v29 child_intent(N_BLOCKS_M);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_v29(intent, j)) continue;

    // 5. Fusión de Bucles (v29 - Prefetching)
    child_extent.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    const auto& attr_j_bits = attr_cols[j];

    // --- ¡LA OPERACIÓN v29! ---
    const int PREFETCH_DISTANCE = 16; // (Distancia de pre-búsqueda)
    const size_t extent_size = extent.size();

    for (size_t i = 0; i < extent_size; ++i) {

      // (A) Instrucción de Prefetch
      // (Le dice al CPU que vaya buscando los datos de la iteración i+16)
      if (i + PREFETCH_DISTANCE < extent_size) {
        const int next_obj_idx = extent[i + PREFETCH_DISTANCE];
        // (Args: dirección, 0=lectura, 0=baja localidad temporal)
        __builtin_prefetch(&obj_rows_flat[next_obj_idx * N_BLOCKS_M], 0, 0);
      }

      // (B) Trabajo Actual (el bucle v23)
      const int obj_idx = extent[i];
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);

        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }
    // --- Fin del bucle v29 ---

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (v23)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;
    for (int b = 0; b < j_block_idx; b++) {
      uint64_t new_bits = child_intent[b] & (~intent[b]);
      if (new_bits != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (1ULL << j_bit_idx) - 1;
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }
    for (size_t b = 0; b < N_BLOCKS_M; ++b) {
      uint64_t candidates = ~intent[b];
      if (b == j_block_idx) { candidates &= ((1ULL << j_bit_idx) - 1); }
      else if (b > j_block_idx) { candidates = 0; }
      (*all_att_intents) += __builtin_popcountll(candidates);
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v29_prefetch(j, n_objects, n_attributes, N_BLOCKS_M,
                                     child_extent, child_intent,
                                     attr_cols, obj_rows_flat,
                                     extents_out, intents_out,
                                     intent_buffer,
                                     extent_x_buffer,
                                     canonicity_tests, all_att_intents);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v29 (Prefetch).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v29(NumericMatrix I,
                                 StringVector attrs,
                                 bool verbose = false) {
  Timer timer;
  timer.step("start_v29_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;

  // 1. Construir representaciones duales (v23)
  AttributeCols attr_cols(n_attributes, Bitset_N(n_objects)); // (Boost)
  ObjectRows_v29_flat obj_rows_flat(n_objects * N_BLOCKS_M, 0); // (Nativa)

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);

        int block_idx_m = c / 64;
        int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_v29 initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_v29_recursion");

  // 5. Iniciar la recursión (versión v29)
  inclose_fast_core_v29_prefetch(-1, n_objects, n_attributes, N_BLOCKS_M,
                                 initial_extent, initial_intent,
                                 attr_cols, obj_rows_flat,
                                 &extents_out, &intents_out,
                                 intent_io_buffer,
                                 extent_x_io_buffer,
                                 &canonicity_tests, &all_att_intents);

  timer.step("end_v29_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN 31 (PRO): (v23 + Transposición de Cache Dinámica) ---
// =============================================================================

// (v31) Tipos Nativos
using ObjectRows_v31_transposed = std::vector<std::vector<uint64_t>>;
using IntentAccumulator_v31 = std::vector<uint64_t>;

// (v31) Testeo nativo de bits (M)
inline bool test_bit_native_M_v31(const IntentAccumulator_v31& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v31 (Transpuesto y Dinámico).
 */
void inclose_fast_core_v31_transposed(int y,
                                      int n_objects,
                                      int n_attributes,
                                      const size_t N_BLOCKS_M,
                                      Extent& extent,
                                      IntentAccumulator_v31& intent,
                                      const AttributeCols& attr_cols, // (Boost)
                                      const ObjectRows_v31_transposed& obj_rows_transposed,
                                      SparseVector* extents_out,
                                      DoubleArray* intents_out,
                                      double* intent_buffer,
                                      double* extent_x_buffer,
                                      double* canonicity_tests,
                                      double* all_att_intents,
                                      std::vector<const uint64_t*>& block_pointers) { // (v31 Búfer de Punteros)

  // 1. E/S Extent (v15)
  size_t n_added = extent.size();
  if (n_added > 0) {
    insertArray_bulk_int_v13(&(extents_out->i), extent.data(), n_added);
    insertArray_bulk_double_v9(&(extents_out->x), extent_x_buffer, n_added);
  }
  if (extents_out->p.used == 0) {
    insertArray(&(extents_out->p), 0);
  }
  int last_p = extents_out->p.array[extents_out->p.used - 1];
  insertArray(&(extents_out->p), last_p + n_added);

  // 2. E/S Intent (v21)
  for (int attr = 0; attr < n_attributes; ++attr) {
    intent_buffer[attr] = test_bit_native_M_v31(intent, attr) ? 1.0 : 0.0;
  }
  insertArray_bulk_double_v9(intents_out, intent_buffer, n_attributes);

  // 3. Asignación de memoria ÚNICA (v23)
  Extent child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_v31 child_intent(N_BLOCKS_M);

  // 4. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_v31(intent, j)) continue;

    // 5. Fusión de Bucles (v31 - Cache Friendly)
    child_extent.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    const auto& attr_j_bits = attr_cols[j];

    for (int obj_idx : extent) {
      if (attr_j_bits.test(obj_idx)) {
        child_extent.push_back(obj_idx);

        // --- ¡LA OPERACIÓN v31! (Acceso L1/L2) ---
        // (Bucle dinámico sobre los punteros de bloque)
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= block_pointers[k][obj_idx];
        }
      }
    }

    if (child_extent.empty()) continue;

    // 6. Test de Canonicidad (v23)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;
    for (int b = 0; b < j_block_idx; b++) {
      uint64_t new_bits = child_intent[b] & (~intent[b]);
      if (new_bits != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (1ULL << j_bit_idx) - 1;
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }
    for (size_t b = 0; b < N_BLOCKS_M; ++b) {
      uint64_t candidates = ~intent[b];
      if (b == j_block_idx) { candidates &= ((1ULL << j_bit_idx) - 1); }
      else if (b > j_block_idx) { candidates = 0; }
      (*all_att_intents) += __builtin_popcountll(candidates);
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_fast_core_v31_transposed(j, n_objects, n_attributes, N_BLOCKS_M,
                                       child_extent, child_intent,
                                       attr_cols, obj_rows_transposed,
                                       extents_out, intents_out,
                                       intent_buffer,
                                       extent_x_buffer,
                                       canonicity_tests, all_att_intents,
                                       block_pointers); // (Pasamos el búfer de punteros)
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v31 (Pro Transposed).
 */
// [[Rcpp::export]]
List InClose_binary_fast_v31(NumericMatrix I,
                                       StringVector attrs,
                                       bool verbose = false) {
  Timer timer;
  timer.step("start_v31_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (v21) Cálculo de bloques
  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;

  // 1. Construir representaciones duales (v31)
  AttributeCols attr_cols(n_attributes, Bitset_N(n_objects)); // (Boost)

  // (v31: Matriz transpuesta de N_BLOCKS_M vectores)
  ObjectRows_v31_transposed obj_rows_transposed(N_BLOCKS_M);
  for(size_t b=0; b < N_BLOCKS_M; ++b) {
    obj_rows_transposed[b].resize(n_objects, 0); // (Relleno con 0)
  }

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        attr_cols[c].set(r);

        // (v31 set_bit transpuesto)
        int block_idx_m = c / 64;
        int bit_idx_m = c % 64;
        obj_rows_transposed[block_idx_m][r] |= (1ULL << bit_idx_m);
      }
    }
  }

  // (v31: Búfer de punteros para acceso L1)
  std::vector<const uint64_t*> block_pointers(N_BLOCKS_M);
  for(size_t k=0; k < N_BLOCKS_M; ++k) {
    block_pointers[k] = obj_rows_transposed[k].data();
  }

  // 2. Inicializar contadores y estructuras de salida
  double canonicity_tests = 0;
  double all_att_intents = 0;
  SparseVector extents_out;
  DoubleArray intents_out;
  initVector(&extents_out, n_objects * 100);
  initArray(&intents_out, n_attributes * 1000);

  // 3. Búferes de E/S (v15)
  double* intent_io_buffer = (double*)calloc(n_attributes, sizeof(double));
  double* extent_x_io_buffer = (double*)calloc(n_objects, sizeof(double));
  if (intent_io_buffer == NULL || extent_x_io_buffer == NULL) {
    Rcpp::stop("Failed to calloc memory for I/O buffers");
  }
  for(int i = 0; i < n_objects; ++i) {
    extent_x_io_buffer[i] = 1.0;
  }

  // 4. Calcular el concepto inicial (Top)
  Extent initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_v31 initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  // (v31: Bucle de caché amigable)
  for (int obj_idx : initial_extent) {
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= block_pointers[k][obj_idx];
    }
  }

  timer.step("start_v31_recursion");

  // 5. Iniciar la recursión (versión v31)
  inclose_fast_core_v31_transposed(-1, n_objects, n_attributes, N_BLOCKS_M,
                                   initial_extent, initial_intent,
                                   attr_cols, obj_rows_transposed,
                                   &extents_out, &intents_out,
                                   intent_io_buffer,
                                   extent_x_io_buffer,
                                   &canonicity_tests, &all_att_intents,
                                   block_pointers); // (Pasamos el búfer de punteros)

  timer.step("end_v31_recursion");

  // 6. Empaquetar resultados
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  // 7. Liberar búferes de E/S
  free(intent_io_buffer);
  free(extent_x_io_buffer);

  freeVector(&extents_out);
  freeArray(&intents_out);

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = (intents_out.used > 0) ? (intents_out.used / n_attributes) : 0,
    _["tests"] = canonicity_tests,
    _["att_intents"] = all_att_intents,
    _["timer"] = timer);
  return res;
}


// =============================================================================
// --- VERSIÓN DE PRODUCCIÓN (NATIVA + E/S AMORTIZADA) ---
// =============================================================================

// --- Definiciones de tipos para v_prod ---
using Extent_Prod = std::vector<int>;
using AttributeCols_Prod = std::vector<uint64_t>;
using ObjectRows_Prod = std::vector<uint64_t>;
using IntentAccumulator_Prod = std::vector<uint64_t>;

// --- Helpers Nativos v_prod ---
inline bool test_bit_native_M_Prod(const IntentAccumulator_Prod& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

inline bool test_bit_native_N_Prod(const AttributeCols_Prod& blocks,
                                   int attr_j, int obj_idx,
                                   const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v_prod (E/S Amortizada, Totalmente Nativo).
 *
 * NO escribe en la salida de R. Escribe en vectores C++ intermedios.
 */
void inclose_core_production(int y,
                             int n_objects,
                             int n_attributes,
                             const size_t N_BLOCKS_M,
                             const size_t N_BLOCKS_N,
                             Extent_Prod& extent,
                             IntentAccumulator_Prod& intent,
                             const AttributeCols_Prod& attr_cols_flat,
                             const ObjectRows_Prod& obj_rows_flat,
                             std::vector<int>& ext_i_out,
                             std::vector<int>& ext_p_out,
                             std::vector<uint64_t>& int_blocks_out,
                             double* canonicity_tests) {

  // 1. Guardar el concepto (E/S Amortizada: solo push/insert)
  ext_p_out.push_back(ext_i_out.size()); // p[j]
  ext_i_out.insert(ext_i_out.end(), extent.begin(), extent.end());
  int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());

  // 2. Asignación de memoria ÚNICA (v23)
  Extent_Prod child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_Prod child_intent(N_BLOCKS_M);

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_Prod(intent, j)) continue;

    // 4. Fusión de Bucles (v27 - Totalmente Nativo)
    child_extent.clear();
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);

    for (int obj_idx : extent) {
      // (Test nativo)
      if (test_bit_native_N_Prod(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);

        // (Intersección nativa)
        const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
        for(size_t k = 0; k < N_BLOCKS_M; ++k) {
          child_intent[k] &= row_ptr[k];
        }
      }
    }

    if (child_extent.empty()) continue;

    // 5. Test de Canonicidad (v28 - Sin contadores)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    for (int b = 0; b < j_block_idx; b++) {
      if ((child_intent[b] & (~intent[b])) != 0) {
        is_canonical = false;
        break;
      }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
        if ((new_bits & mask) != 0) {
          is_canonical = false;
        }
      }
    }
    // (Contador 'all_att_intents' ELIMINADO)

    // 6. Recursión
    if (is_canonical) {
      inclose_core_production(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                              child_extent, child_intent,
                              attr_cols_flat, obj_rows_flat,
                              ext_i_out, ext_p_out, int_blocks_out,
                              canonicity_tests);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v_prod (Producción).
 */
// [[Rcpp::export]]
List InClose_Production(NumericMatrix I,
                        StringVector attrs,
                        bool verbose = false) {
  Timer timer;
  timer.step("start_prod_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (v22) Cálculo de bloques
  const size_t N_BLOCKS_M = (n_attributes + 63) / 64; // Para Intents
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;   // Para Extents

  // 1. Construir representaciones duales (NATIVAS v22)
  AttributeCols_Prod attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_Prod obj_rows_flat(n_objects * N_BLOCKS_M, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y E/S C++ (v3)
  double canonicity_tests = 0;

  std::vector<int> ext_i_out;
  std::vector<int> ext_p_out;
  std::vector<uint64_t> int_blocks_out;

  // (Pre-reserva agresiva para evitar reallocs)
  size_t estimated_concepts = (n_objects * n_attributes) / 4;
  if (estimated_concepts < 1000) estimated_concepts = 1000;
  ext_i_out.reserve(estimated_concepts * n_objects / 4); // Estimación
  ext_p_out.reserve(estimated_concepts + 1);
  int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);


  // 3. Calcular el concepto inicial (Top)
  Extent_Prod initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_Prod initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_prod_recursion");

  // 4. Iniciar la recursión (versión v_prod)
  inclose_core_production(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                          initial_extent, initial_intent,
                          attr_cols_flat, obj_rows_flat,
                          ext_i_out, ext_p_out, int_blocks_out,
                          &canonicity_tests);

  timer.step("end_prod_recursion");

  // 5. *** EMPAQUETADO A GRANEL (E/S Amortizada) ***

  // (A) Preparar Extents
  SparseVector extents_out;
  initVector(&extents_out, 0);

  // (A.1) Copiar 'i' (índices)
  size_t total_nnz = ext_i_out.size();
  ensureArray_int_v10(&(extents_out.i), total_nnz);
  memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
  extents_out.i.used = total_nnz;

  // (A.2) Copiar 'p' (punteros)
  ext_p_out.push_back(total_nnz); // El último p[n_col]
  size_t total_p = ext_p_out.size();
  ensureArray_int_v10(&(extents_out.p), total_p);
  memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
  extents_out.p.used = total_p;

  // (A.3) Crear y copiar 'x' (valores 1.0)
  ensureArray_double_v9(&(extents_out.x), total_nnz);
  std::fill_n(extents_out.x.array, total_nnz, 1.0);
  extents_out.x.used = total_nnz;

  // (B) Preparar Intents
  DoubleArray intents_out;
  initArray(&intents_out, 0);

  size_t total_concepts = ext_p_out.size() - 1;
  size_t total_int_doubles = total_concepts * n_attributes;
  ensureArray_double_v9(&intents_out, total_int_doubles);

  double* intent_out_ptr = intents_out.array;

  for(size_t c = 0; c < total_concepts; ++c) {
    const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
    for (int attr = 0; attr < n_attributes; ++attr) {
      int block_idx = attr / 64;
      int bit_idx = attr % 64;
      if ((block_ptr[block_idx] & (1ULL << bit_idx)) != 0) {
        *intent_out_ptr = 1.0;
      }
      // (el array ya está inicializado a 0 por ensureArray_double_v9)
      intent_out_ptr++;
    }
  }
  intents_out.used = total_int_doubles;

  // (C) Empaquetar en S4
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_prod_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0, // (Sacrificado por rendimiento)
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN ULTIMATE (NATIVA + E/S AMORTIZADA + CACHÉ COHERENTE) ---
// =============================================================================

// --- Definiciones de tipos para v_ultimate ---
using Extent_Ultimate = std::vector<int>;
using AttributeCols_Ultimate = std::vector<uint64_t>;
using ObjectRows_Ultimate = std::vector<uint64_t>;
using IntentAccumulator_Ultimate = std::vector<uint64_t>;

// --- Helpers Nativos v_ultimate ---
inline bool test_bit_native_M_Ultimate(const IntentAccumulator_Ultimate& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

inline bool test_bit_native_N_Ultimate(const AttributeCols_Ultimate& blocks,
                                       int attr_j, int obj_idx,
                                       const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v_ultimate (Separación de Bucles para Caché).
 */
void inclose_core_ultimate(int y,
                           int n_objects,
                           int n_attributes,
                           const size_t N_BLOCKS_M,
                           const size_t N_BLOCKS_N,
                           Extent_Ultimate& extent,
                           IntentAccumulator_Ultimate& intent,
                           const AttributeCols_Ultimate& attr_cols_flat,
                           const ObjectRows_Ultimate& obj_rows_flat,
                           std::vector<int>& ext_i_out,
                           std::vector<int>& ext_p_out,
                           std::vector<uint64_t>& int_blocks_out,
                           double* canonicity_tests) {

  // 1. Guardar el concepto (E/S Amortizada v_prod)
  ext_p_out.push_back(ext_i_out.size());
  ext_i_out.insert(ext_i_out.end(), extent.begin(), extent.end());
  int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());

  // 2. Asignación de memoria ÚNICA (v_prod)
  Extent_Ultimate child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_Ultimate child_intent(N_BLOCKS_M);

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_Ultimate(intent, j)) continue;

    // 4. *** OPTIMIZACIÓN v_ultimate: SEPARACIÓN DE BUCLES ***

    // 4a. Bucle 1: Filtrado (Cache-friendly en attr_cols_flat)
    // Coste: O(|extent|)
    child_extent.clear();
    for (int obj_idx : extent) {
      if (test_bit_native_N_Ultimate(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 4b. Bucle 2: Intersección (Cache-friendly en obj_rows_flat)
    // Coste: O(|child_extent| * M/64)
    std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);
    for (int obj_idx : child_extent) {
      const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
      for(size_t k = 0; k < N_BLOCKS_M; ++k) {
        child_intent[k] &= row_ptr[k];
      }
    }

    // 5. Test de Canonicidad (v_prod / v28)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    for (int b = 0; b < j_block_idx; b++) {
      if ((child_intent[b] & (~intent[b])) != 0) {
        is_canonical = false;
        break;
      }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
        if ((new_bits & mask) != 0) {
          is_canonical = false;
        }
      }
    }

    // 6. Recursión
    if (is_canonical) {
      inclose_core_ultimate(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                            child_extent, child_intent,
                            attr_cols_flat, obj_rows_flat,
                            ext_i_out, ext_p_out, int_blocks_out,
                            canonicity_tests);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v_ultimate (Producción).
 * * NOTA: ¡Esta función requiere los helpers de E/S a granel
 * (ensureArray_double_v9, ensureArray_int_v10, insertArray_bulk_int_v13)
 * definidos en la respuesta anterior (sección v23)!
 */
// [[Rcpp::export]]
List InClose_Ultimate(NumericMatrix I,
                      StringVector attrs,
                      bool verbose = false) {
  Timer timer;
  timer.step("start_ultimate_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  // (v22) Cálculo de bloques
  const size_t N_BLOCKS_M = (n_attributes + 63) / 64; // Para Intents
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;   // Para Extents

  // 1. Construir representaciones duales (NATIVAS v_prod)
  AttributeCols_Ultimate attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_Ultimate obj_rows_flat(n_objects * N_BLOCKS_M, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y E/S C++ (v_prod)
  double canonicity_tests = 0;

  std::vector<int> ext_i_out;
  std::vector<int> ext_p_out;
  std::vector<uint64_t> int_blocks_out;

  // (Pre-reserva)
  size_t estimated_concepts = (n_objects * n_attributes) / 4;
  if (estimated_concepts < 1000) estimated_concepts = 1000;
  ext_i_out.reserve(estimated_concepts * n_objects / 4);
  ext_p_out.reserve(estimated_concepts + 1);
  int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);


  // 3. Calcular el concepto inicial (Top)
  Extent_Ultimate initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_Ultimate initial_intent(N_BLOCKS_M);
  std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);

  for (int obj_idx : initial_extent) {
    const uint64_t* row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      initial_intent[k] &= row_ptr[k];
    }
  }

  timer.step("start_ultimate_recursion");

  // 4. Iniciar la recursión (versión v_ultimate)
  inclose_core_ultimate(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                        initial_extent, initial_intent,
                        attr_cols_flat, obj_rows_flat,
                        ext_i_out, ext_p_out, int_blocks_out,
                        &canonicity_tests);

  timer.step("end_ultimate_recursion");

  // 5. EMPAQUETADO A GRANEL (v_prod)

  // (A) Preparar Extents
  SparseVector extents_out;
  initVector(&extents_out, 0);

  size_t total_nnz = ext_i_out.size();
  ensureArray_int_v10(&(extents_out.i), total_nnz);
  memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
  extents_out.i.used = total_nnz;

  ext_p_out.push_back(total_nnz); // El último p[n_col]
  size_t total_p = ext_p_out.size();
  ensureArray_int_v10(&(extents_out.p), total_p);
  memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
  extents_out.p.used = total_p;

  ensureArray_double_v9(&(extents_out.x), total_nnz);
  std::fill_n(extents_out.x.array, total_nnz, 1.0);
  extents_out.x.used = total_nnz;

  // (B) Preparar Intents
  DoubleArray intents_out;
  initArray(&intents_out, 0);

  size_t total_concepts = ext_p_out.size() - 1;
  size_t total_int_doubles = total_concepts * n_attributes;
  ensureArray_double_v9(&intents_out, total_int_doubles);

  double* intent_out_ptr = intents_out.array;

  for(size_t c = 0; c < total_concepts; ++c) {
    const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
    for (int attr = 0; attr < n_attributes; ++attr) {
      int block_idx = attr / 64;
      int bit_idx = attr % 64;
      if ((block_ptr[block_idx] & (1ULL << bit_idx)) != 0) {
        *intent_out_ptr = 1.0;
      }
      intent_out_ptr++;
    }
  }
  intents_out.used = total_int_doubles;

  // (C) Empaquetar en S4
  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_ultimate_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0, // (Sacrificado)
    _["timer"] = timer);
  return res;
}


// // =============================================================================
// // --- VERSIÓN SIMD (AVX2 + NEON): (v_prod + Vectorización Híbrida) ---
// // =============================================================================
//
// // --- (NUEVO) DEFINICIÓN GLOBAL DE ALINEACIÓN ---
// const size_t SIMD_ALIGNMENT = 32;
//
// // --- (MOVIDO) HELPER ALLOCATOR (ÁMBITO GLOBAL) ---
// // (Requerido por C++ para std::vector con memoria alineada)
// template <typename T, size_t N = SIMD_ALIGNMENT>
// class AlignedAllocator {
// public:
//   typedef T value_type;
//   typedef T* pointer;
//   typedef const T* const_pointer;
//   typedef void* void_pointer;
//   typedef const void* const_void_pointer;
//   typedef size_t size_type;
//   typedef ptrdiff_t difference_type;
//
//   template <typename U>
//   struct rebind {
//     typedef AlignedAllocator<U, N> other;
//   };
//
//   AlignedAllocator() {}
//   template <typename U>
//   AlignedAllocator(const AlignedAllocator<U, N>&) {}
//
//   pointer address(T& r) const { return &r; }
//   const_pointer address(const T& s) const { return &s; }
//
//   pointer allocate(size_type n, const_void_pointer = 0) {
//     void* p;
// #ifdef _WIN32
//     p = _aligned_malloc(n * sizeof(T), N);
//     if (!p) throw std::bad_alloc();
// #else
//     // (posix_memalign es el estándar en Linux/macOS)
//     if (posix_memalign(&p, N, n * sizeof(T)) != 0) {
//       p = 0; throw std::bad_alloc();
//     }
// #endif
//     return static_cast<pointer>(p);
//   }
//
//   void deallocate(pointer p, size_type) {
// #ifdef _WIN32
//     _aligned_free(p);
// #else
//     free(p);
// #endif
//   }
//
//   void construct(pointer p, const T& t) { new (p) T(t); }
//   void destroy(pointer p) { p->~T(); }
//   size_type max_size() const { return size_type(-1) / sizeof(T); }
// };
//
//
// // --- Definiciones de tipos para v_simd ---
// using Extent_SIMD = std::vector<int>;
// using AttributeCols_SIMD = std::vector<uint64_t>;
// // ¡Puntero! La memoria la gestionaremos manualmente.
// using ObjectRows_SIMD = uint64_t*;
// // (Usamos el allocator alineado para el 'intent' principal)
// using IntentAccumulator_SIMD = std::vector<uint64_t, AlignedAllocator<uint64_t>>;
//
//
// // --- Helpers Nativos v_simd ---
// inline bool test_bit_native_M_SIMD(const IntentAccumulator_SIMD& blocks, int k) {
//   int block_idx = k / 64;
//   int bit_idx = k % 64;
//   if (block_idx >= blocks.size()) return false;
//   return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
// }
//
// inline bool test_bit_native_N_SIMD(const AttributeCols_SIMD& blocks,
//                                    int attr_j, int obj_idx,
//                                    const size_t N_BLOCKS_N) {
//   int block_idx = obj_idx / 64;
//   int bit_idx = obj_idx % 64;
//   return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
// }
//
//
// /**
//  * @brief Core recursivo v_simd (Híbrido AVX2 + NEON).
//  */
// void inclose_core_simd(int y,
//                        int n_objects,
//                        int n_attributes,
//                        const size_t N_BLOCKS_M,
//                        const size_t N_BLOCKS_N,
//                        Extent_SIMD& extent,
//                        IntentAccumulator_SIMD& intent,
//                        const AttributeCols_SIMD& attr_cols_flat,
//                        const ObjectRows_SIMD obj_rows_flat, // (Puntero)
//                        std::vector<int>& ext_i_out,
//                        std::vector<int>& ext_p_out,
//                        std::vector<uint64_t>& int_blocks_out,
//                        double* canonicity_tests) {
//
//   // 1. Guardar el concepto (E/S Amortizada v_prod)
//   ext_p_out.push_back(ext_i_out.size());
//   ext_i_out.insert(ext_i_out.end(), extent.begin(), extent.end());
//   int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());
//
//   // 2. Asignación de memoria ÚNICA (v_prod)
//   Extent_SIMD child_extent;
//   child_extent.reserve(extent.size());
//   // (El 'child_intent' se crea en la pila del bucle, pero usa el allocator alineado)
//   IntentAccumulator_SIMD child_intent(N_BLOCKS_M);
//
//   // 3. Iterar sobre atributos 'j'
//   for (int j = y + 1; j < n_attributes; j++) {
//     if (test_bit_native_M_SIMD(intent, j)) continue;
//
//     // 4. Bucle Fusionado (v_prod)
//     child_extent.clear();
//     std::fill(child_intent.begin(), child_intent.end(), 0xFFFFFFFFFFFFFFFF);
//
//     // (Punteros para el bucle SIMD)
//     uint64_t* __restrict__ child_intent_ptr = child_intent.data();
//
//     for (int obj_idx : extent) {
//       if (test_bit_native_N_SIMD(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
//         child_extent.push_back(obj_idx);
//
//         const uint64_t* __restrict__ row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
//
//         // 5. *** ¡EL TRABAJO SIMD (HÍBRIDO)! ***
//         size_t k = 0;
//
//         // --- (A) Rama AVX2 (Intel/AMD) ---
// #if defined(__x86_64__) || defined(_M_X64)
//         size_t limit_k_avx2 = (N_BLOCKS_M / 4) * 4; // 4x 64-bit
//         for (; k < limit_k_avx2; k += 4) {
//           __m256i intent_blocks = _mm256_load_si256((__m256i const*)(child_intent_ptr + k));
//           __m256i row_blocks = _mm256_load_si256((__m256i const*)(row_ptr + k));
//           intent_blocks = _mm256_and_si256(intent_blocks, row_blocks);
//           _mm256_store_si256((__m256i*)(child_intent_ptr + k), intent_blocks);
//         }
//
//         // --- (B) Rama NEON (Apple Silicon M1/M2/M3) ---
// #elif defined(__aarch64__) || defined(_M_ARM64)
//         size_t limit_k_neon = (N_BLOCKS_M / 2) * 2; // 2x 64-bit (128-bit regs)
//         for (; k < limit_k_neon; k += 2) {
//           uint64x2_t intent_blocks = vld1q_u64(child_intent_ptr + k);
//           uint64x2_t row_blocks = vld1q_u64(row_ptr + k);
//           intent_blocks = vandq_u64(intent_blocks, row_blocks);
//           vst1q_u64(child_intent_ptr + k, intent_blocks);
//         }
// #endif
//
//         // --- (C) Cola (para cualquier arquitectura) ---
//         for (; k < N_BLOCKS_M; ++k) {
//           child_intent_ptr[k] &= row_ptr[k];
//         }
//       }
//     }
//
//     if (child_extent.empty()) continue;
//
//     // 6. Test de Canonicidad (v_prod / v28)
//     (*canonicity_tests) += 1.0;
//     bool is_canonical = true;
//     const int j_block_idx = j / 64;
//     const int j_bit_idx = j % 64;
//
//     for (int b = 0; b < j_block_idx; b++) {
//       if ((child_intent[b] & (~intent[b])) != 0) { is_canonical = false; break; }
//     }
//     if (is_canonical) {
//       uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
//       if (new_bits != 0) {
//         uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
//         if ((new_bits & mask) != 0) { is_canonical = false; }
//       }
//     }
//     // (Contador 'all_att_intents' ELIMINADO)
//
//     // 7. Recursión
//     if (is_canonical) {
//       inclose_core_simd(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
//                         child_extent, child_intent,
//                         attr_cols_flat, obj_rows_flat,
//                         ext_i_out, ext_p_out, int_blocks_out,
//                         canonicity_tests);
//     }
//   }
// }
//
//
// /**
//  * @brief Wrapper Rcpp para el algoritmo In-Close v_simd (AVX2 + NEON).
//  */
// // [[Rcpp::export]]
// List InClose_SIMD(NumericMatrix I,
//                   StringVector attrs,
//                   bool verbose = false) {
//   Timer timer;
//   timer.step("start_simd_setup");
//   int n_objects = I.nrow();
//   int n_attributes = I.ncol();
//
//   const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
//   const size_t N_BLOCKS_N = (n_objects + 63) / 64;
//
//   // 1. Construir representaciones duales
//   AttributeCols_SIMD attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
//   ObjectRows_SIMD obj_rows_flat = nullptr;
//   size_t total_obj_blocks = (size_t)n_objects * N_BLOCKS_M;
//
//   // (Usamos la constante global SIMD_ALIGNMENT)
// #ifdef _WIN32
//   obj_rows_flat = (uint64_t*)_aligned_malloc(total_obj_blocks * sizeof(uint64_t), SIMD_ALIGNMENT);
// #else
//   if (posix_memalign((void**)&obj_rows_flat, SIMD_ALIGNMENT, total_obj_blocks * sizeof(uint64_t)) != 0) {
//     obj_rows_flat = nullptr;
//   }
// #endif
//
//   if (obj_rows_flat == nullptr) {
//     Rcpp::stop("Failed to allocate aligned memory for obj_rows_flat.");
//   }
//   std::fill_n(obj_rows_flat, total_obj_blocks, 0);
//
//
//   for (int r = 0; r < n_objects; ++r) {
//     for (int c = 0; c < n_attributes; ++c) {
//       if (I(r, c) == 1.0) {
//         int block_idx_n = r / 64; int bit_idx_n = r % 64;
//         attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
//         int block_idx_m = c / 64; int bit_idx_m = c % 64;
//         obj_rows_flat[r * N_BLOCKS_M + block_idx_m] |= (1ULL << bit_idx_m);
//       }
//     }
//   }
//
//   // 2. Inicializar contadores y E/S C++
//   double canonicity_tests = 0;
//   std::vector<int> ext_i_out;
//   std::vector<int> ext_p_out;
//   std::vector<uint64_t> int_blocks_out;
//
//   size_t estimated_concepts = (n_objects * n_attributes) / 4;
//   if (estimated_concepts < 1000) estimated_concepts = 1000;
//   ext_i_out.reserve(estimated_concepts * n_objects / 4);
//   ext_p_out.reserve(estimated_concepts + 1);
//   int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);
//
//   // 3. Calcular el concepto inicial (Top)
//   Extent_SIMD initial_extent;
//   initial_extent.reserve(n_objects);
//   for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);
//
//   // (Declaramos el intent con el allocator alineado)
//   // (Esto ahora funcionará porque AlignedAllocator está en el ámbito global)
//   IntentAccumulator_SIMD initial_intent(N_BLOCKS_M);
//   std::fill(initial_intent.begin(), initial_intent.end(), 0xFFFFFFFFFFFFFFFF);
//
//   // --- ¡CÁLCULO INICIAL HÍBRIDO! ---
//   for (int obj_idx : initial_extent) {
//     const uint64_t* __restrict__ row_ptr = &obj_rows_flat[obj_idx * N_BLOCKS_M];
//     uint64_t* __restrict__ intent_ptr = initial_intent.data();
//
//     size_t k = 0;
//
//     // (A) Rama AVX2
// #if defined(__x86_64__) || defined(_M_X64)
//     size_t limit_k_avx2 = (N_BLOCKS_M / 4) * 4;
//     for (; k < limit_k_avx2; k += 4) {
//       __m256i intent_blocks = _mm256_load_si256((__m256i const*)(intent_ptr + k));
//       __m256i row_blocks = _mm256_load_si256((__m256i const*)(row_ptr + k));
//       intent_blocks = _mm256_and_si256(intent_blocks, row_blocks);
//       _mm256_store_si256((__m256i*)(intent_ptr + k), intent_blocks);
//     }
//
//     // (B) Rama NEON
// #elif defined(__aarch64__) || defined(_M_ARM64)
//     size_t limit_k_neon = (N_BLOCKS_M / 2) * 2;
//     for (; k < limit_k_neon; k += 2) {
//       uint64x2_t intent_blocks = vld1q_u64(intent_ptr + k);
//       uint64x2_t row_blocks = vld1q_u64(row_ptr + k);
//       intent_blocks = vandq_u64(intent_blocks, row_blocks);
//       vst1q_u64(intent_ptr + k, intent_blocks);
//     }
// #endif
//
//     // (C) Cola
//     for (; k < N_BLOCKS_M; ++k) {
//       intent_ptr[k] &= row_ptr[k];
//     }
//   }
//
//   timer.step("start_simd_recursion");
//
//   // 4. Iniciar la recursión (versión v_simd)
//   inclose_core_simd(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
//                     initial_extent, initial_intent,
//                     attr_cols_flat, obj_rows_flat,
//                     ext_i_out, ext_p_out, int_blocks_out,
//                     &canonicity_tests);
//
//   timer.step("end_simd_recursion");
//
//   // 5. EMPAQUETADO A GRANEL (v_prod)
//   SparseVector extents_out;
//   initVector(&extents_out, 0);
//   size_t total_nnz = ext_i_out.size();
//   ensureArray_int_v10(&(extents_out.i), total_nnz);
//   memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
//   extents_out.i.used = total_nnz;
//   ext_p_out.push_back(total_nnz);
//   size_t total_p = ext_p_out.size();
//   ensureArray_int_v10(&(extents_out.p), total_p);
//   memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
//   extents_out.p.used = total_p;
//   ensureArray_double_v9(&(extents_out.x), total_nnz);
//   std::fill_n(extents_out.x.array, total_nnz, 1.0);
//   extents_out.x.used = total_nnz;
//
//   DoubleArray intents_out;
//   initArray(&intents_out, 0);
//   size_t total_concepts = ext_p_out.size() - 1;
//   size_t total_int_doubles = total_concepts * n_attributes;
//   ensureArray_double_v9(&intents_out, total_int_doubles);
//   double* intent_out_ptr = intents_out.array;
//   for(size_t c = 0; c < total_concepts; ++c) {
//     const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
//     for (int attr = 0; attr < n_attributes; ++attr) {
//       int block_idx = attr / 64;
//       int bit_idx = attr % 64;
//       if ((block_ptr[block_idx] & (1ULL << bit_idx)) != 0) {
//         *intent_out_ptr = 1.0;
//       }
//       intent_out_ptr++;
//     }
//   }
//   intents_out.used = total_int_doubles;
//
//   S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
//   S4 extents_S4 = SparseToS4_fast(extents_out);
//
//   freeVector(&extents_out);
//   freeArray(&intents_out);
//
//   // 6. ¡Liberar la memoria alineada!
// #ifdef _WIN32
//   _aligned_free(obj_rows_flat);
// #else
//   free(obj_rows_flat);
// #endif
//
//   timer.step("end_simd_packaging");
//
//   List res = List::create(
//     _["intents"] = intents_S4,
//     _["extents"] = extents_S4,
//     _["total"] = total_concepts,
//     _["tests"] = canonicity_tests,
//     _["att_intents"] = 0, // (Sacrificado)
//     _["timer"] = timer);
//   return res;
// }


// =============================================================================
// --- VERSIÓN TRANSPOSE (v_ultim + v31 + v_prod) ---
// =============================================================================

// --- Definiciones de tipos para v_transpose ---
using Extent_Transpose = std::vector<int>;
using AttributeCols_Transpose = std::vector<uint64_t>;
using ObjectRows_Transpose = std::vector<uint64_t>; // [bloque][objeto]
using IntentAccumulator_Transpose = std::vector<uint64_t>;

// --- Helpers Nativos v_transpose ---
// (test_bit_native_M_Ultimate es reutilizable, renombrado)
inline bool test_bit_native_M_Transpose(const IntentAccumulator_Transpose& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (test_bit_native_N_Ultimate es reutilizable, renombrado)
inline bool test_bit_native_N_Transpose(const AttributeCols_Transpose& blocks,
                                        int attr_j, int obj_idx,
                                        const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}


/**
 * @brief Core recursivo v_transpose (Caché Secuencial).
 */
void inclose_core_transpose(int y,
                            int n_objects,
                            int n_attributes,
                            const size_t N_BLOCKS_M,
                            const size_t N_BLOCKS_N,
                            Extent_Transpose& extent,
                            IntentAccumulator_Transpose& intent,
                            const AttributeCols_Transpose& attr_cols_flat,
                            const ObjectRows_Transpose& obj_rows_transposed,
                            std::vector<int>& ext_i_out,
                            std::vector<int>& ext_p_out,
                            std::vector<uint64_t>& int_blocks_out,
                            double* canonicity_tests) {

  // 1. Guardar el concepto (E/S Amortizada v_prod)
  ext_p_out.push_back(ext_i_out.size());
  ext_i_out.insert(ext_i_out.end(), extent.begin(), extent.end());
  int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());

  // 2. Asignación de memoria ÚNICA (v_prod)
  Extent_Transpose child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_Transpose child_intent(N_BLOCKS_M);

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_Transpose(intent, j)) continue;

    // 4. *** ALGORITMO v_ultim (Bucles Separados) ***

    // 4a. Bucle 1: Filtrado (Acceso aleatorio a attr_cols)
    child_extent.clear();
    for (int obj_idx : extent) {
      if (test_bit_native_N_Transpose(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 4b. Bucle 2: Intersección (¡Acceso SECUENCIAL a obj_rows!)
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      // Puntero al inicio del Bloque 'k'
      const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
      uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;

      // ¡Este bucle interno es ahora cache-friendly!
      for (int obj_idx : child_extent) {
        intent_k &= row_k_ptr[obj_idx];
      }
      child_intent[k] = intent_k;
    }

    // 5. Test de Canonicidad (v_prod / v28)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    for (int b = 0; b < j_block_idx; b++) {
      if ((child_intent[b] & (~intent[b])) != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }

    // 6. Recursión
    if (is_canonical) {
      inclose_core_transpose(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                             child_extent, child_intent,
                             attr_cols_flat, obj_rows_transposed,
                             ext_i_out, ext_p_out, int_blocks_out,
                             canonicity_tests);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v_transpose (Producción).
 * * NOTA: ¡Esta función requiere los helpers de E/S a granel!
 */
// [[Rcpp::export]]
List InClose_Transpose(NumericMatrix I,
                       StringVector attrs,
                       bool verbose = false) {
  Timer timer;
  timer.step("start_transpose_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;

  // 1. Construir representaciones duales (NATIVAS)
  AttributeCols_Transpose attr_cols_flat(n_attributes * N_BLOCKS_N, 0);

  // ¡¡ESTRUCTURA TRANSPUESTA!!
  ObjectRows_Transpose obj_rows_transposed(N_BLOCKS_M * n_objects, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        // attr_cols (sin cambios)
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);

        // obj_rows (transpuesto)
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_transposed[block_idx_m * n_objects + r] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y E/S C++
  double canonicity_tests = 0;
  std::vector<int> ext_i_out;
  std::vector<int> ext_p_out;
  std::vector<uint64_t> int_blocks_out;

  size_t estimated_concepts = (n_objects * n_attributes) / 4;
  if (estimated_concepts < 1000) estimated_concepts = 1000;
  ext_i_out.reserve(estimated_concepts * n_objects / 4);
  ext_p_out.reserve(estimated_concepts + 1);
  int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);

  // 3. Calcular el concepto inicial (Top)
  Extent_Transpose initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_Transpose initial_intent(N_BLOCKS_M);

  // (Cálculo inicial transpuesto)
  for(size_t k = 0; k < N_BLOCKS_M; ++k) {
    const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
    uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;
    for (int obj_idx : initial_extent) {
      intent_k &= row_k_ptr[obj_idx];
    }
    initial_intent[k] = intent_k;
  }

  timer.step("start_transpose_recursion");

  // 4. Iniciar la recursión
  inclose_core_transpose(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                         initial_extent, initial_intent,
                         attr_cols_flat, obj_rows_transposed,
                         ext_i_out, ext_p_out, int_blocks_out,
                         &canonicity_tests);

  timer.step("end_transpose_recursion");

  // 5. EMPAQUETADO A GRANEL (v_prod)
  SparseVector extents_out;
  initVector(&extents_out, 0);
  size_t total_nnz = ext_i_out.size();
  ensureArray_int_v10(&(extents_out.i), total_nnz);
  memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
  extents_out.i.used = total_nnz;
  ext_p_out.push_back(total_nnz);
  size_t total_p = ext_p_out.size();
  ensureArray_int_v10(&(extents_out.p), total_p);
  memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
  extents_out.p.used = total_p;
  ensureArray_double_v9(&(extents_out.x), total_nnz);
  std::fill_n(extents_out.x.array, total_nnz, 1.0);
  extents_out.x.used = total_nnz;

  DoubleArray intents_out;
  initArray(&intents_out, 0);
  size_t total_concepts = ext_p_out.size() - 1;
  size_t total_int_doubles = total_concepts * n_attributes;
  ensureArray_double_v9(&intents_out, total_int_doubles);
  double* intent_out_ptr = intents_out.array;
  for(size_t c = 0; c < total_concepts; ++c) {
    const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
    for (int attr = 0; attr < n_attributes; ++attr) {
      int block_idx = attr / 64;
      int bit_idx = attr % 64;
      if ((block_ptr[block_idx] & (1ULL << bit_idx)) != 0) {
        *intent_out_ptr = 1.0;
      }
      intent_out_ptr++;
    }
  }
  intents_out.used = total_int_doubles;

  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_transpose_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0,
    _["timer"] = timer);
  return res;
}


// =============================================================================
// --- VERSIÓN HYBRID (v_transpose + v_dense_filter) ---
// =============================================================================

// --- Definiciones de tipos para v_hybrid ---
using Extent_Hybrid_Sparse = std::vector<int>;
using Extent_Hybrid_Dense = std::vector<uint64_t>; // ¡NUEVO!
using AttributeCols_Hybrid = std::vector<uint64_t>;
using ObjectRows_Hybrid = std::vector<uint64_t>;
using IntentAccumulator_Hybrid = std::vector<uint64_t>;

// --- Helpers Nativos v_hybrid ---
inline bool test_bit_native_M_Hybrid(const IntentAccumulator_Hybrid& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (Helper para el Bucle 2 de Conversión)
inline bool test_bit_native_N_acc_Hybrid(const Extent_Hybrid_Dense& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

/**
 * @brief Core recursivo v_hybrid (Doble Representación).
 */
void inclose_core_hybrid(int y,
                         int n_objects,
                         int n_attributes,
                         const size_t N_BLOCKS_M,
                         const size_t N_BLOCKS_N,
                         Extent_Hybrid_Sparse& extent_sparse, // (Para Intersección)
                         Extent_Hybrid_Dense& extent_dense,   // (Para Filtrado)
                         IntentAccumulator_Hybrid& intent,
                         const AttributeCols_Hybrid& attr_cols_flat,
                         const ObjectRows_Hybrid& obj_rows_transposed,
                         std::vector<int>& ext_i_out,
                         std::vector<int>& ext_p_out,
                         std::vector<uint64_t>& int_blocks_out,
                         double* canonicity_tests) {

  // 1. Guardar el concepto (E/S Amortizada v_prod)
  // (Usamos el extent_sparse que ya tenemos)
  ext_p_out.push_back(ext_i_out.size());
  ext_i_out.insert(ext_i_out.end(), extent_sparse.begin(), extent_sparse.end());
  int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());

  // 2. Asignación de memoria ÚNICA (v_prod)
  Extent_Hybrid_Sparse child_extent_sparse;
  child_extent_sparse.reserve(extent_sparse.size());
  Extent_Hybrid_Dense child_extent_dense(N_BLOCKS_N); // ¡Denso!
  IntentAccumulator_Hybrid child_intent(N_BLOCKS_M);

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_Hybrid(intent, j)) continue;

    // 4. *** ALGORITMO HÍBRIDO ***

    // 4a. Bucle 1: Filtrado Denso (O(N/64) - SECUENCIAL)
    const uint64_t* attr_j_ptr = &attr_cols_flat[j * N_BLOCKS_N];
    bool is_empty = true;
    for(size_t k = 0; k < N_BLOCKS_N; ++k) {
      child_extent_dense[k] = extent_dense[k] & attr_j_ptr[k];
      if (child_extent_dense[k] != 0) is_empty = false;
    }

    if (is_empty) continue;

    // 4b. Bucle 2: Conversión Denso -> Disperso (O(N) - SECUENCIAL)
    child_extent_sparse.clear();
    for (int obj_idx = 0; obj_idx < n_objects; ++obj_idx) {
      // (Usamos el helper _acc_ para testear el bitset denso)
      if (test_bit_native_N_acc_Hybrid(child_extent_dense, obj_idx)) {
        child_extent_sparse.push_back(obj_idx);
      }
    }
    // (child_extent_sparse.empty() ya está cubierto por is_empty)

    // 4c. Bucle 3: Intersección Dispersa (O(M/64 * |child|) - SECUENCIAL)
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
      uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;
      for (int obj_idx : child_extent_sparse) {
        intent_k &= row_k_ptr[obj_idx];
      }
      child_intent[k] = intent_k;
    }

    // 5. Test de Canonicidad (v_prod / v28)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    for (int b = 0; b < j_block_idx; b++) {
      if ((child_intent[b] & (~intent[b])) != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }

    // 6. Recursión
    if (is_canonical) {
      inclose_core_hybrid(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                          child_extent_sparse, child_extent_dense, // Pasamos AMBOS
                          child_intent,
                          attr_cols_flat, obj_rows_transposed,
                          ext_i_out, ext_p_out, int_blocks_out,
                          canonicity_tests);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v_hybrid (Producción).
 * * NOTA: ¡Esta función requiere los helpers de E/S a granel!
 */
// [[Rcpp::export]]
List InClose_Hybrid(NumericMatrix I,
                    StringVector attrs,
                    bool verbose = false) {
  Timer timer;
  timer.step("start_hybrid_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;

  // 1. Construir representaciones duales (NATIVAS)
  AttributeCols_Hybrid attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_Hybrid obj_rows_transposed(N_BLOCKS_M * n_objects, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_transposed[block_idx_m * n_objects + r] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y E/S C++
  double canonicity_tests = 0;
  std::vector<int> ext_i_out;
  std::vector<int> ext_p_out;
  std::vector<uint64_t> int_blocks_out;

  size_t estimated_concepts = (n_objects * n_attributes) / 4;
  if (estimated_concepts < 1000) estimated_concepts = 1000;
  ext_i_out.reserve(estimated_concepts * n_objects / 4);
  ext_p_out.reserve(estimated_concepts + 1);
  int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);

  // 3. Calcular el concepto inicial (Top)
  // (Versión Dispersa)
  Extent_Hybrid_Sparse initial_extent_sparse;
  initial_extent_sparse.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent_sparse.push_back(i);

  // (Versión Densa)
  Extent_Hybrid_Dense initial_extent_dense(N_BLOCKS_N);
  std::fill(initial_extent_dense.begin(), initial_extent_dense.end(), 0xFFFFFFFFFFFFFFFF);

  IntentAccumulator_Hybrid initial_intent(N_BLOCKS_M);

  // (Cálculo inicial transpuesto)
  for(size_t k = 0; k < N_BLOCKS_M; ++k) {
    const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
    uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;
    for (int obj_idx : initial_extent_sparse) {
      intent_k &= row_k_ptr[obj_idx];
    }
    initial_intent[k] = intent_k;
  }

  // (Sincronizar el extent denso inicial con el intent)
  // (Esto es O(M * N/64) pero solo se hace UNA VEZ)
  std::fill(initial_extent_dense.begin(), initial_extent_dense.end(), 0xFFFFFFFFFFFFFFFF);
  for(size_t j = 0; j < n_attributes; ++j) {
    if (test_bit_native_M_Hybrid(initial_intent, j)) {
      const uint64_t* col_ptr = &attr_cols_flat[j * N_BLOCKS_N];
      for(size_t k=0; k < N_BLOCKS_N; ++k) {
        initial_extent_dense[k] &= col_ptr[k];
      }
    }
  }

  // (Sincronizar el extent disperso inicial)
  // (Esto es O(N) pero solo se hace UNA VEZ)
  initial_extent_sparse.clear();
  for(int i=0; i < n_objects; ++i) {
    if(test_bit_native_N_acc_Hybrid(initial_extent_dense, i)) {
      initial_extent_sparse.push_back(i);
    }
  }

  timer.step("start_hybrid_recursion");

  // 4. Iniciar la recursión
  inclose_core_hybrid(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                      initial_extent_sparse, initial_extent_dense, // Pasamos AMBOS
                      initial_intent,
                      attr_cols_flat, obj_rows_transposed,
                      ext_i_out, ext_p_out, int_blocks_out,
                      &canonicity_tests);

  timer.step("end_hybrid_recursion");

  // 5. EMPAQUETADO A GRANEL (v_prod)
  SparseVector extents_out;
  initVector(&extents_out, 0);
  size_t total_nnz = ext_i_out.size();
  ensureArray_int_v10(&(extents_out.i), total_nnz);
  memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
  extents_out.i.used = total_nnz;
  ext_p_out.push_back(total_nnz);
  size_t total_p = ext_p_out.size();
  ensureArray_int_v10(&(extents_out.p), total_p);
  memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
  extents_out.p.used = total_p;
  ensureArray_double_v9(&(extents_out.x), total_nnz);
  std::fill_n(extents_out.x.array, total_nnz, 1.0);
  extents_out.x.used = total_nnz;

  DoubleArray intents_out;
  initArray(&intents_out, 0);
  size_t total_concepts = ext_p_out.size() - 1;
  size_t total_int_doubles = total_concepts * n_attributes;
  ensureArray_double_v9(&intents_out, total_int_doubles);
  double* intent_out_ptr = intents_out.array;
  for(size_t c = 0; c < total_concepts; ++c) {
    const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
    for (int attr = 0; attr < n_attributes; ++attr) {
      int block_idx = attr / 64;
      int bit_idx = attr % 64;
      if ((block_ptr[block_idx] & (1ULL << bit_idx)) != 0) {
        *intent_out_ptr = 1.0;
      }
      intent_out_ptr++;
    }
  }
  intents_out.used = total_int_doubles;

  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_hybrid_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN PRUNE (v_transpose + Poda "FastClose") ---
// =============================================================================

// --- Definiciones de tipos para v_prune ---
using Extent_Prune = std::vector<int>;
using AttributeCols_Prune = std::vector<uint64_t>;
using ObjectRows_Prune = std::vector<uint64_t>; // [bloque][objeto]
using IntentAccumulator_Prune = std::vector<uint64_t>;

// --- Helpers Nativos v_prune ---
inline bool test_bit_native_M_Prune(const IntentAccumulator_Prune& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

inline bool test_bit_native_N_Prune(const AttributeCols_Prune& blocks,
                                    int attr_j, int obj_idx,
                                    const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}


/**
 * @brief Core recursivo v_prune (v_transpose + Poda).
 */
void inclose_core_prune(int y,
                        int n_objects,
                        int n_attributes,
                        const size_t N_BLOCKS_M,
                        const size_t N_BLOCKS_N,
                        Extent_Prune& extent,
                        IntentAccumulator_Prune& intent,
                        const AttributeCols_Prune& attr_cols_flat,
                        const ObjectRows_Prune& obj_rows_transposed,
                        std::vector<int>& ext_i_out,
                        std::vector<int>& ext_p_out,
                        std::vector<uint64_t>& int_blocks_out,
                        double* canonicity_tests) {

  // 1. Guardar el concepto (E/S Amortizada v_prod)
  ext_p_out.push_back(ext_i_out.size());
  ext_i_out.insert(ext_i_out.end(), extent.begin(), extent.end());
  int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());

  // 2. Asignación de memoria ÚNICA
  Extent_Prune child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_Prune child_intent(N_BLOCKS_M);

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_Prune(intent, j)) continue;

    // 4a. Bucle 1: Filtrado (v_transpose)
    child_extent.clear();
    for (int obj_idx : extent) {
      if (test_bit_native_N_Prune(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 4b. Bucle 2: Intersección (v_transpose)
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
      uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;
      for (int obj_idx : child_extent) {
        intent_k &= row_k_ptr[obj_idx];
      }
      child_intent[k] = intent_k;
    }

    // 5. *** ¡OPTIMIZACIÓN DE PODA! ***
    // (Comprobamos si child_intent == intent)
    bool is_equal = true;
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      if (child_intent[k] != intent[k]) {
        is_equal = false;
        break;
      }
    }
    if (is_equal) continue; // ¡PODA! (El concepto no es canónico)


    // 6. Test de Canonicidad (v_prod / v28)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    for (int b = 0; b < j_block_idx; b++) {
      if ((child_intent[b] & (~intent[b])) != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }

    // 7. Recursión
    if (is_canonical) {
      inclose_core_prune(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                         child_extent, child_intent,
                         attr_cols_flat, obj_rows_transposed,
                         ext_i_out, ext_p_out, int_blocks_out,
                         canonicity_tests);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v_prune (Producción).
 * * NOTA: ¡Esta función requiere los helpers de E/S a granel!
 */
// [[Rcpp::export]]
List InClose_Prune(NumericMatrix I,
                   StringVector attrs,
                   bool verbose = false) {
  Timer timer;
  timer.step("start_prune_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;

  // 1. Construir representaciones duales (NATIVAS + TRANSPUESTA)
  AttributeCols_Prune attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_Prune obj_rows_transposed(N_BLOCKS_M * n_objects, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_transposed[block_idx_m * n_objects + r] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y E/S C++
  double canonicity_tests = 0;
  std::vector<int> ext_i_out;
  std::vector<int> ext_p_out;
  std::vector<uint64_t> int_blocks_out;

  size_t estimated_concepts = (n_objects * n_attributes) / 4;
  if (estimated_concepts < 1000) estimated_concepts = 1000;
  ext_i_out.reserve(estimated_concepts * n_objects / 4);
  ext_p_out.reserve(estimated_concepts + 1);
  int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);

  // 3. Calcular el concepto inicial (Top)
  Extent_Prune initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_Prune initial_intent(N_BLOCKS_M);

  for(size_t k = 0; k < N_BLOCKS_M; ++k) {
    const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
    uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;
    for (int obj_idx : initial_extent) {
      intent_k &= row_k_ptr[obj_idx];
    }
    initial_intent[k] = intent_k;
  }

  timer.step("start_prune_recursion");

  // 4. Iniciar la recursión
  inclose_core_prune(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                     initial_extent, initial_intent,
                     attr_cols_flat, obj_rows_transposed,
                     ext_i_out, ext_p_out, int_blocks_out,
                     &canonicity_tests);

  timer.step("end_prune_recursion");

  // 5. EMPAQUETADO A GRANEL (v_prod)
  SparseVector extents_out;
  initVector(&extents_out, 0);
  size_t total_nnz = ext_i_out.size();
  ensureArray_int_v10(&(extents_out.i), total_nnz);
  memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
  extents_out.i.used = total_nnz;
  ext_p_out.push_back(total_nnz);
  size_t total_p = ext_p_out.size();
  ensureArray_int_v10(&(extents_out.p), total_p);
  memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
  extents_out.p.used = total_p;
  ensureArray_double_v9(&(extents_out.x), total_nnz);
  std::fill_n(extents_out.x.array, total_nnz, 1.0);
  extents_out.x.used = total_nnz;

  DoubleArray intents_out;
  initArray(&intents_out, 0);
  size_t total_concepts = ext_p_out.size() - 1;
  size_t total_int_doubles = total_concepts * n_attributes;
  ensureArray_double_v9(&intents_out, total_int_doubles);
  double* intent_out_ptr = intents_out.array;
  for(size_t c = 0; c < total_concepts; ++c) {
    const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
    for (int attr = 0; attr < n_attributes; ++attr) {
      int block_idx = attr / 64;
      int bit_idx = attr % 64;
      if ((block_ptr[block_idx] & (1ULL << bit_idx)) != 0) {
        *intent_out_ptr = 1.0;
      }
      intent_out_ptr++;
    }
  }
  intents_out.used = total_int_doubles;

  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_prune_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0,
    _["timer"] = timer);
  return res;
}


// =============================================================================
// --- VERSIÓN PREFETCH (v_transpose + Prefetching Manual) ---
// =============================================================================

// --- Definiciones de tipos para v_prefetch ---
using Extent_Prefetch = std::vector<int>;
using AttributeCols_Prefetch = std::vector<uint64_t>;
using ObjectRows_Prefetch = std::vector<uint64_t>; // [bloque][objeto]
using IntentAccumulator_Prefetch = std::vector<uint64_t>;

// --- Helpers Nativos v_prefetch ---
inline bool test_bit_native_M_Prefetch(const IntentAccumulator_Prefetch& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

inline bool test_bit_native_N_Prefetch(const AttributeCols_Prefetch& blocks,
                                       int attr_j, int obj_idx,
                                       const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}


/**
 * @brief Core recursivo v_prefetch (v_transpose + Prefetch).
 */
void inclose_core_prefetch(int y,
                           int n_objects,
                           int n_attributes,
                           const size_t N_BLOCKS_M,
                           const size_t N_BLOCKS_N,
                           Extent_Prefetch& extent,
                           IntentAccumulator_Prefetch& intent,
                           const AttributeCols_Prefetch& attr_cols_flat,
                           const ObjectRows_Prefetch& obj_rows_transposed,
                           std::vector<int>& ext_i_out,
                           std::vector<int>& ext_p_out,
                           std::vector<uint64_t>& int_blocks_out,
                           double* canonicity_tests) {

  // 1. Guardar el concepto (E/S Amortizada v_prod)
  ext_p_out.push_back(ext_i_out.size());
  ext_i_out.insert(ext_i_out.end(), extent.begin(), extent.end());
  int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());

  // 2. Asignación de memoria ÚNICA
  Extent_Prefetch child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_Prefetch child_intent(N_BLOCKS_M);

  // (Distancia de pre-búsqueda, 8-16 suele ser un buen valor)
  const int PREFETCH_DISTANCE = 8;

  // 3. Iterar sobre atributos 'j'
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_Prefetch(intent, j)) continue;

    // 4. *** ALGORITMO v_transpose ***

    // 4a. Bucle 1: Filtrado (con Prefetch)
    child_extent.clear();
    const size_t extent_size = extent.size();

    for (size_t i = 0; i < extent_size; ++i) {
      const int obj_idx = extent[i];

      // --- ¡PREFETCH BUClE 1! ---
      // Traemos el dato de attr_cols que necesitaremos en 8 iteraciones
      if (i + PREFETCH_DISTANCE < extent_size) {
        const int next_obj_idx = extent[i + PREFETCH_DISTANCE];
        const int next_block_idx = next_obj_idx / 64;
        // (Args: dirección, 0=lectura, 0=baja localidad temporal)
        __builtin_prefetch(&attr_cols_flat[j * N_BLOCKS_N + next_block_idx], 0, 0);
      }

      // (Trabajo actual)
      if (test_bit_native_N_Prefetch(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue;

    // 4b. Bucle 2: Intersección (con Prefetch)
    const size_t child_extent_size = child_extent.size();

    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
      uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;

      for (size_t i = 0; i < child_extent_size; ++i) {
        const int obj_idx = child_extent[i];

        // --- ¡PREFETCH BUClE 2! ---
        if (i + PREFETCH_DISTANCE < child_extent_size) {
          const int next_obj_idx = child_extent[i + PREFETCH_DISTANCE];
          __builtin_prefetch(&row_k_ptr[next_obj_idx], 0, 0);
        }

        // (Trabajo actual)
        intent_k &= row_k_ptr[obj_idx];
      }
      child_intent[k] = intent_k;
    }

    // 5. Test de Canonicidad (v_prod / v28)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    for (int b = 0; b < j_block_idx; b++) {
      if ((child_intent[b] & (~intent[b])) != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }

    // 6. Recursión
    if (is_canonical) {
      inclose_core_prefetch(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                            child_extent, child_intent,
                            attr_cols_flat, obj_rows_transposed,
                            ext_i_out, ext_p_out, int_blocks_out,
                            canonicity_tests);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v_prefetch (Producción).
 * * NOTA: ¡Esta función requiere los helpers de E/S a granel!
 */
// [[Rcpp::export]]
List InClose_Prefetch(NumericMatrix I,
                      StringVector attrs,
                      bool verbose = false) {
  Timer timer;
  timer.step("start_prefetch_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;

  // 1. Construir representaciones duales (NATIVAS + TRANSPUESTA)
  AttributeCols_Prefetch attr_cols_flat(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_Prefetch obj_rows_transposed(N_BLOCKS_M * n_objects, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c = 0; c < n_attributes; ++c) {
      if (I(r, c) == 1.0) {
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_flat[c * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);
        int block_idx_m = c / 64; int bit_idx_m = c % 64;
        obj_rows_transposed[block_idx_m * n_objects + r] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 2. Inicializar contadores y E/S C++
  double canonicity_tests = 0;
  std::vector<int> ext_i_out;
  std::vector<int> ext_p_out;
  std::vector<uint64_t> int_blocks_out;

  size_t estimated_concepts = (n_objects * n_attributes) / 4;
  if (estimated_concepts < 1000) estimated_concepts = 1000;
  ext_i_out.reserve(estimated_concepts * n_objects / 4);
  ext_p_out.reserve(estimated_concepts + 1);
  int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);

  // 3. Calcular el concepto inicial (Top)
  Extent_Prefetch initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_Prefetch initial_intent(N_BLOCKS_M);

  // --- ¡¡CORRECCIÓN!! Definimos la constante aquí ---
  const int PREFETCH_DISTANCE = 8;

  const size_t initial_extent_size = initial_extent.size();
  for(size_t k = 0; k < N_BLOCKS_M; ++k) {
    const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
    uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;

    // (Prefetch en el bucle inicial también)
    for (size_t i = 0; i < initial_extent_size; ++i) {
      const int obj_idx = initial_extent[i];
      if (i + PREFETCH_DISTANCE < initial_extent_size) {
        const int next_obj_idx = initial_extent[i + PREFETCH_DISTANCE];
        __builtin_prefetch(&row_k_ptr[next_obj_idx], 0, 0);
      }
      intent_k &= row_k_ptr[obj_idx];
    }
    initial_intent[k] = intent_k;
  }

  timer.step("start_prefetch_recursion");

  // 4. Iniciar la recursión
  inclose_core_prefetch(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                        initial_extent, initial_intent,
                        attr_cols_flat, obj_rows_transposed,
                        ext_i_out, ext_p_out, int_blocks_out,
                        &canonicity_tests);

  timer.step("end_prefetch_recursion");

  // 5. EMPAQUETADO A GRANEL (v_prod)
  SparseVector extents_out;
  initVector(&extents_out, 0);
  size_t total_nnz = ext_i_out.size();
  ensureArray_int_v10(&(extents_out.i), total_nnz);
  memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
  extents_out.i.used = total_nnz;
  ext_p_out.push_back(total_nnz);
  size_t total_p = ext_p_out.size();
  ensureArray_int_v10(&(extents_out.p), total_p);
  memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
  extents_out.p.used = total_p;
  ensureArray_double_v9(&(extents_out.x), total_nnz);
  std::fill_n(extents_out.x.array, total_nnz, 1.0);
  extents_out.x.used = total_nnz;

  DoubleArray intents_out;
  initArray(&intents_out, 0);
  size_t total_concepts = ext_p_out.size() - 1;
  size_t total_int_doubles = total_concepts * n_attributes;
  ensureArray_double_v9(&intents_out, total_int_doubles);
  double* intent_out_ptr = intents_out.array;
  for(size_t c = 0; c < total_concepts; ++c) {
    const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
    for (int attr = 0; attr < n_attributes; ++attr) {
      int block_idx = attr / 64;
      int bit_idx = attr % 64;
      if ((block_ptr[block_idx] & (1ULL << bit_idx)) != 0) {
        *intent_out_ptr = 1.0;
      }
      intent_out_ptr++;
    }
  }
  intents_out.used = total_int_doubles;

  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_prefetch_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0,
    _["timer"] = timer);
  return res;
}

// =============================================================================
// --- VERSIÓN REORDER (v_transpose + Reordenación de Atributos) ---
// =============================================================================

// --- Definiciones de tipos para v_reorder ---
using Extent_Reorder = std::vector<int>;
using AttributeCols_Reorder = std::vector<uint64_t>;
using ObjectRows_Reorder = std::vector<uint64_t>; // [bloque][objeto]
using IntentAccumulator_Reorder = std::vector<uint64_t>;

// --- Helpers Nativos v_reorder ---
inline bool test_bit_native_M_Reorder(const IntentAccumulator_Reorder& blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  if (block_idx >= blocks.size()) return false;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

// (Helper para el bitset de 'intent' plano)
inline bool test_bit_native_M_Reorder_flat(const uint64_t* blocks, int k) {
  int block_idx = k / 64;
  int bit_idx = k % 64;
  return (blocks[block_idx] & (1ULL << bit_idx)) != 0;
}

inline bool test_bit_native_N_Reorder(const AttributeCols_Reorder& blocks,
                                      int attr_j, int obj_idx,
                                      const size_t N_BLOCKS_N) {
  int block_idx = obj_idx / 64;
  int bit_idx = obj_idx % 64;
  return (blocks[attr_j * N_BLOCKS_N + block_idx] & (1ULL << bit_idx)) != 0;
}


/**
 * @brief Core recursivo v_reorder (Idéntico a v_transpose).
 * El núcleo no necesita saber que los datos están reordenados.
 */
void inclose_core_reorder(int y,
                          int n_objects,
                          int n_attributes,
                          const size_t N_BLOCKS_M,
                          const size_t N_BLOCKS_N,
                          Extent_Reorder& extent,
                          IntentAccumulator_Reorder& intent,
                          const AttributeCols_Reorder& attr_cols_flat,
                          const ObjectRows_Reorder& obj_rows_transposed,
                          std::vector<int>& ext_i_out,
                          std::vector<int>& ext_p_out,
                          std::vector<uint64_t>& int_blocks_out,
                          double* canonicity_tests) {

  // 1. Guardar el concepto (E/S Amortizada)
  ext_p_out.push_back(ext_i_out.size());
  ext_i_out.insert(ext_i_out.end(), extent.begin(), extent.end());
  int_blocks_out.insert(int_blocks_out.end(), intent.begin(), intent.end());

  // 2. Asignación de memoria ÚNICA
  Extent_Reorder child_extent;
  child_extent.reserve(extent.size());
  IntentAccumulator_Reorder child_intent(N_BLOCKS_M);

  // 3. Iterar sobre atributos 'j' (AHORA ORDENADOS POR SOPORTE)
  for (int j = y + 1; j < n_attributes; j++) {
    if (test_bit_native_M_Reorder(intent, j)) continue;

    // 4a. Bucle 1: Filtrado
    child_extent.clear();
    for (int obj_idx : extent) {
      if (test_bit_native_N_Reorder(attr_cols_flat, j, obj_idx, N_BLOCKS_N)) {
        child_extent.push_back(obj_idx);
      }
    }

    if (child_extent.empty()) continue; // (Esto ocurrirá mucho más a menudo)

    // 4b. Bucle 2: Intersección (v_transpose)
    for(size_t k = 0; k < N_BLOCKS_M; ++k) {
      const uint64_t* row_k_ptr = &obj_rows_transposed[k * n_objects];
      uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;
      for (int obj_idx : child_extent) {
        intent_k &= row_k_ptr[obj_idx];
      }
      child_intent[k] = intent_k;
    }

    // 5. Test de Canonicidad (v_prod / v28)
    (*canonicity_tests) += 1.0;
    bool is_canonical = true;
    const int j_block_idx = j / 64;
    const int j_bit_idx = j % 64;

    for (int b = 0; b < j_block_idx; b++) {
      if ((child_intent[b] & (~intent[b])) != 0) { is_canonical = false; break; }
    }
    if (is_canonical) {
      uint64_t new_bits = child_intent[j_block_idx] & (~intent[j_block_idx]);
      if (new_bits != 0) {
        uint64_t mask = (j_bit_idx == 0) ? 0 : ((1ULL << j_bit_idx) - 1);
        if ((new_bits & mask) != 0) { is_canonical = false; }
      }
    }

    // 6. Recursión
    if (is_canonical) {
      inclose_core_reorder(j, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                           child_extent, child_intent,
                           attr_cols_flat, obj_rows_transposed,
                           ext_i_out, ext_p_out, int_blocks_out,
                           canonicity_tests);
    }
  }
}


/**
 * @brief Wrapper Rcpp para el algoritmo In-Close v_reorder (Producción).
 * * NOTA: ¡Esta función requiere los helpers de E/S a granel!
 */
// [[Rcpp::export]]
List InClose_Reorder(NumericMatrix I,
                     StringVector attrs,
                     bool verbose = false) {
  Timer timer;
  timer.step("start_reorder_setup");
  int n_objects = I.nrow();
  int n_attributes = I.ncol();

  const size_t N_BLOCKS_M = (n_attributes + 63) / 64;
  const size_t N_BLOCKS_N = (n_objects + 63) / 64;

  // 1. *** ¡NUEVO! CÁLCULO DE SOPORTE Y REORDENACIÓN ***
  std::vector<std::pair<int, int>> attr_support(n_attributes);
  for (int c = 0; c < n_attributes; ++c) {
    attr_support[c].second = c; // Índice original
    int support = 0;
    for (int r = 0; r < n_objects; ++r) {
      if (I(r, c) == 1.0) support++;
    }
    attr_support[c].first = support; // Conteo (soporte)
  }

  // Ordenar por soporte (menor a mayor)
  std::sort(attr_support.begin(), attr_support.end());

  // Crear mapas de reordenación
  std::vector<int> new_to_old_attr(n_attributes);
  std::vector<int> old_to_new_attr(n_attributes);
  for (int j = 0; j < n_attributes; ++j) {
    int original_idx = attr_support[j].second;
    new_to_old_attr[j] = original_idx;
    old_to_new_attr[original_idx] = j;
  }

  // 2. Construir representaciones duales (YA REORDENADAS)
  AttributeCols_Reorder attr_cols_reordered(n_attributes * N_BLOCKS_N, 0);
  ObjectRows_Reorder obj_rows_reordered_transposed(N_BLOCKS_M * n_objects, 0);

  for (int r = 0; r < n_objects; ++r) {
    for (int c_orig = 0; c_orig < n_attributes; ++c_orig) {
      if (I(r, c_orig) == 1.0) {
        int c_new = old_to_new_attr[c_orig]; // Obtener el nuevo índice (ordenado)

        // Poner en attr_cols_reordered
        int block_idx_n = r / 64; int bit_idx_n = r % 64;
        attr_cols_reordered[c_new * N_BLOCKS_N + block_idx_n] |= (1ULL << bit_idx_n);

        // Poner en obj_rows_reordered_transposed
        int block_idx_m = c_new / 64; int bit_idx_m = c_new % 64;
        obj_rows_reordered_transposed[block_idx_m * n_objects + r] |= (1ULL << bit_idx_m);
      }
    }
  }

  // 3. Inicializar contadores y E/S C++
  double canonicity_tests = 0;
  std::vector<int> ext_i_out;
  std::vector<int> ext_p_out;
  std::vector<uint64_t> int_blocks_out;

  size_t estimated_concepts = (n_objects * n_attributes) / 4;
  if (estimated_concepts < 1000) estimated_concepts = 1000;
  ext_i_out.reserve(estimated_concepts * n_objects / 4);
  ext_p_out.reserve(estimated_concepts + 1);
  int_blocks_out.reserve(estimated_concepts * N_BLOCKS_M);

  // 4. Calcular el concepto inicial (Top)
  Extent_Reorder initial_extent;
  initial_extent.reserve(n_objects);
  for(int i = 0; i < n_objects; ++i) initial_extent.push_back(i);

  IntentAccumulator_Reorder initial_intent(N_BLOCKS_M);

  for(size_t k = 0; k < N_BLOCKS_M; ++k) {
    const uint64_t* row_k_ptr = &obj_rows_reordered_transposed[k * n_objects];
    uint64_t intent_k = 0xFFFFFFFFFFFFFFFF;
    for (int obj_idx : initial_extent) {
      intent_k &= row_k_ptr[obj_idx];
    }
    initial_intent[k] = intent_k;
  }

  timer.step("start_reorder_recursion");

  // 5. Iniciar la recursión (con datos reordenados)
  inclose_core_reorder(-1, n_objects, n_attributes, N_BLOCKS_M, N_BLOCKS_N,
                       initial_extent, initial_intent,
                       attr_cols_reordered, obj_rows_reordered_transposed,
                       ext_i_out, ext_p_out, int_blocks_out,
                       &canonicity_tests);

  timer.step("end_reorder_recursion");

  // 6. EMPAQUETADO A GRANEL (¡CON DE-REORDENACIÓN!)
  SparseVector extents_out;
  initVector(&extents_out, 0);
  size_t total_nnz = ext_i_out.size();
  ensureArray_int_v10(&(extents_out.i), total_nnz);
  memcpy(extents_out.i.array, ext_i_out.data(), total_nnz * sizeof(int));
  extents_out.i.used = total_nnz;
  ext_p_out.push_back(total_nnz);
  size_t total_p = ext_p_out.size();
  ensureArray_int_v10(&(extents_out.p), total_p);
  memcpy(extents_out.p.array, ext_p_out.data(), total_p * sizeof(int));
  extents_out.p.used = total_p;
  ensureArray_double_v9(&(extents_out.x), total_nnz);
  std::fill_n(extents_out.x.array, total_nnz, 1.0);
  extents_out.x.used = total_nnz;

  DoubleArray intents_out;
  initArray(&intents_out, 0);
  size_t total_concepts = ext_p_out.size() - 1;
  size_t total_int_doubles = total_concepts * n_attributes;
  ensureArray_double_v9(&intents_out, total_int_doubles);
  double* intent_out_ptr = intents_out.array;

  // (Buffer temporal para des-reordenar cada intent)
  std::vector<double> temp_intent(n_attributes);

  for(size_t c = 0; c < total_concepts; ++c) {
    const uint64_t* block_ptr = &int_blocks_out[c * N_BLOCKS_M];
    std::fill(temp_intent.begin(), temp_intent.end(), 0.0); // Reset a 0s

    // 1. Decodificar el intent ORDENADO
    for (int j_new = 0; j_new < n_attributes; ++j_new) {
      if (test_bit_native_M_Reorder_flat(block_ptr, j_new)) {
        // 2. Mapear al índice ORIGINAL
        int j_orig = new_to_old_attr[j_new];
        temp_intent[j_orig] = 1.0;
      }
    }

    // 3. Copiar el intent DES-ORDENADO al array de salida
    memcpy(intent_out_ptr, temp_intent.data(), n_attributes * sizeof(double));
    intent_out_ptr += n_attributes;
  }
  intents_out.used = total_int_doubles;

  S4 intents_S4 = DenseArrayToS4(intents_out, n_attributes);
  S4 extents_S4 = SparseToS4_fast(extents_out);

  freeVector(&extents_out);
  freeArray(&intents_out);

  timer.step("end_reorder_packaging");

  List res = List::create(
    _["intents"] = intents_S4,
    _["extents"] = extents_S4,
    _["total"] = total_concepts,
    _["tests"] = canonicity_tests,
    _["att_intents"] = 0,
    _["timer"] = timer);
  return res;
}
